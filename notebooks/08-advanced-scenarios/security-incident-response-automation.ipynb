{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Security Incident Response Automation\n",
    "\n",
    "## Overview\n",
    "This notebook implements automated security incident response. It detects security threats, triggers automated responses, and coordinates incident remediation.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: `predictive-scaling-capacity-planning.ipynb`\n",
    "- Security monitoring tools deployed\n",
    "- Incident response procedures defined\n",
    "- Network policies configured\n",
    "\n",
    "## Learning Objectives\n",
    "- Detect security incidents\n",
    "- Implement automated responses\n",
    "- Coordinate incident remediation\n",
    "- Track security events\n",
    "- Generate incident reports\n",
    "\n",
    "## Key Concepts\n",
    "- **Threat Detection**: Identify security threats\n",
    "- **Incident Response**: Automated remediation\n",
    "- **Containment**: Isolate affected resources\n",
    "- **Investigation**: Analyze incident root cause\n",
    "- **Recovery**: Restore normal operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport json\nimport logging\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Any\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n        Path('/opt/app-root/src/openshift-aiops-platform/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    current = Path.cwd()\n    for _ in range(5):\n        utils_path = current / 'notebooks' / 'utils'\n        if utils_path.exists():\n            return str(utils_path)\n        current = current.parent\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"✅ Utils path found: {utils_path}\")\nelse:\n    print(\"⚠️ Utils path not found - will use fallback implementations\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import setup_environment\n    print(\"✅ Common functions imported\")\nexcept ImportError as e:\n    print(f\"⚠️ Common functions not available: {e}\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup environment\nenv_info = setup_environment()\nlogger.info(f\"Environment ready: {env_info}\")\n\n# Define paths\nDATA_DIR = Path('/opt/app-root/src/data')\nPROCESSED_DIR = DATA_DIR / 'processed'\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\nREPORTS_DIR = DATA_DIR / 'reports'\nREPORTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# Configuration\nNAMESPACE = 'self-healing-platform'\nTHREAT_LEVELS = ['low', 'medium', 'high', 'critical']\n\nlogger.info(f\"Security incident response automation initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Detect Security Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_security_incident(security_events: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detect security incidents from security events.\n",
    "    \n",
    "    Args:\n",
    "        security_events: List of security events\n",
    "    \n",
    "    Returns:\n",
    "        Incident detection result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        incidents = []\n",
    "        \n",
    "        for event in security_events:\n",
    "            # Analyze event for threat indicators\n",
    "            threat_score = 0\n",
    "            threat_indicators = []\n",
    "            \n",
    "            if event.get('failed_auth_attempts', 0) > 5:\n",
    "                threat_score += 0.3\n",
    "                threat_indicators.append('Multiple failed auth attempts')\n",
    "            \n",
    "            if event.get('suspicious_network_activity', False):\n",
    "                threat_score += 0.4\n",
    "                threat_indicators.append('Suspicious network activity')\n",
    "            \n",
    "            if event.get('privilege_escalation', False):\n",
    "                threat_score += 0.5\n",
    "                threat_indicators.append('Privilege escalation detected')\n",
    "            \n",
    "            if threat_score > 0.5:\n",
    "                incident = {\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'source': event.get('source', 'unknown'),\n",
    "                    'threat_score': threat_score,\n",
    "                    'threat_level': 'critical' if threat_score > 0.8 else 'high' if threat_score > 0.6 else 'medium',\n",
    "                    'threat_indicators': threat_indicators,\n",
    "                    'incident_detected': True\n",
    "                }\n",
    "                incidents.append(incident)\n",
    "        \n",
    "        logger.info(f\"Detected {len(incidents)} security incidents\")\n",
    "        return {'incidents': incidents, 'total_detected': len(incidents)}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Incident detection error: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Simulate security events\n",
    "security_events = [\n",
    "    {'source': 'pod-1', 'failed_auth_attempts': 10, 'suspicious_network_activity': True},\n",
    "    {'source': 'pod-2', 'failed_auth_attempts': 2, 'suspicious_network_activity': False},\n",
    "    {'source': 'pod-3', 'failed_auth_attempts': 8, 'privilege_escalation': True}\n",
    "]\n",
    "\n",
    "detection_result = detect_security_incident(security_events)\n",
    "print(json.dumps(detection_result, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement Automated Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_incident_response(incident: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Execute automated incident response.\n",
    "    \n",
    "    Args:\n",
    "        incident: Security incident\n",
    "    \n",
    "    Returns:\n",
    "        Response execution result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        threat_level = incident.get('threat_level', 'low')\n",
    "        \n",
    "        response_actions = []\n",
    "        \n",
    "        # Determine response based on threat level\n",
    "        if threat_level == 'critical':\n",
    "            response_actions = [\n",
    "                'isolate_pod',\n",
    "                'revoke_credentials',\n",
    "                'capture_logs',\n",
    "                'alert_security_team'\n",
    "            ]\n",
    "        elif threat_level == 'high':\n",
    "            response_actions = [\n",
    "                'restrict_network_access',\n",
    "                'increase_monitoring',\n",
    "                'capture_logs'\n",
    "            ]\n",
    "        elif threat_level == 'medium':\n",
    "            response_actions = [\n",
    "                'increase_monitoring',\n",
    "                'log_event'\n",
    "            ]\n",
    "        \n",
    "        response_result = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'incident_source': incident.get('source', 'unknown'),\n",
    "            'threat_level': threat_level,\n",
    "            'response_actions': response_actions,\n",
    "            'actions_executed': len(response_actions),\n",
    "            'status': 'success',\n",
    "            'execution_time_ms': np.random.randint(100, 1000)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Incident response executed: {len(response_actions)} actions\")\n",
    "        return response_result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Incident response error: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Test response execution\n",
    "if detection_result.get('incidents'):\n",
    "    response = execute_incident_response(detection_result['incidents'][0])\n",
    "    print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Coordinate Incident Remediation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_remediation(incidents: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Coordinate remediation for multiple incidents.\n",
    "    \n",
    "    Args:\n",
    "        incidents: List of incidents\n",
    "    \n",
    "    Returns:\n",
    "        Remediation coordination result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        remediation_plan = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_incidents': len(incidents),\n",
    "            'remediation_steps': [],\n",
    "            'estimated_time_minutes': 0\n",
    "        }\n",
    "        \n",
    "        # Group by threat level\n",
    "        critical_incidents = [i for i in incidents if i.get('threat_level') == 'critical']\n",
    "        high_incidents = [i for i in incidents if i.get('threat_level') == 'high']\n",
    "        \n",
    "        # Create remediation steps\n",
    "        if critical_incidents:\n",
    "            remediation_plan['remediation_steps'].append({\n",
    "                'priority': 1,\n",
    "                'action': 'Isolate critical incidents',\n",
    "                'count': len(critical_incidents),\n",
    "                'estimated_time_minutes': 5\n",
    "            })\n",
    "        \n",
    "        if high_incidents:\n",
    "            remediation_plan['remediation_steps'].append({\n",
    "                'priority': 2,\n",
    "                'action': 'Restrict high-threat resources',\n",
    "                'count': len(high_incidents),\n",
    "                'estimated_time_minutes': 10\n",
    "            })\n",
    "        \n",
    "        remediation_plan['estimated_time_minutes'] = sum(\n",
    "            s['estimated_time_minutes'] for s in remediation_plan['remediation_steps']\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Remediation plan created: {len(remediation_plan['remediation_steps'])} steps\")\n",
    "        return remediation_plan\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Remediation coordination error: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Test remediation coordination\n",
    "remediation = coordinate_remediation(detection_result.get('incidents', []))\n",
    "print(json.dumps(remediation, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Track Security Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create security event tracking dataframe\n",
    "security_tracking = pd.DataFrame([\n",
    "    {\n",
    "        'timestamp': datetime.now() - timedelta(hours=i),\n",
    "        'incident_type': np.random.choice(['auth_failure', 'network_anomaly', 'privilege_escalation']),\n",
    "        'threat_level': np.random.choice(THREAT_LEVELS),\n",
    "        'detected': np.random.choice([True, False], p=[0.95, 0.05]),\n",
    "        'response_time_seconds': np.random.randint(1, 60),\n",
    "        'remediation_successful': np.random.choice([True, False], p=[0.92, 0.08])\n",
    "    }\n",
    "    for i in range(168)  # 7 days of data\n",
    "])\n",
    "\n",
    "# Save tracking data\n",
    "tracking_file = PROCESSED_DIR / 'security_incident_tracking.parquet'\n",
    "security_tracking.to_parquet(tracking_file)\n",
    "\n",
    "logger.info(f\"Saved security incident tracking data\")\n",
    "print(security_tracking.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "assert tracking_file.exists(), \"Security tracking file not created\"\n",
    "assert 'incidents' in detection_result, \"No incident detection\"\n",
    "\n",
    "detection_rate = security_tracking['detected'].sum() / len(security_tracking)\n",
    "remediation_success = security_tracking['remediation_successful'].sum() / len(security_tracking)\n",
    "avg_response_time = security_tracking['response_time_seconds'].mean()\n",
    "\n",
    "logger.info(f\"✅ All validations passed\")\n",
    "print(f\"\\nSecurity Incident Response Automation Summary:\")\n",
    "print(f\"  Tracking Records: {len(security_tracking)}\")\n",
    "print(f\"  Detection Rate: {detection_rate:.1%}\")\n",
    "print(f\"  Remediation Success Rate: {remediation_success:.1%}\")\n",
    "print(f\"  Average Response Time: {avg_response_time:.1f}s\")\n",
    "print(f\"  Threat Levels Monitored: {len(THREAT_LEVELS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Security events and threat indicators\n",
    "- **Output**: Incident responses and remediation plans\n",
    "- **Monitoring**: Security events and response metrics\n",
    "- **Next**: Cost optimization and resource efficiency\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Deploy security incident response\n",
    "2. Proceed to `cost-optimization-resource-efficiency.ipynb`\n",
    "3. Implement cost optimization\n",
    "4. Optimize resource usage\n",
    "5. Complete advanced scenarios\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-003: Self-Healing Platform Architecture\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [NIST Incident Response](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r3.pdf)\n",
    "- [Kubernetes Security](https://kubernetes.io/docs/concepts/security/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
