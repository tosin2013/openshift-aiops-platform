{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pod Crash Loop Healing\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates automatic detection and healing of pod crash loops. It monitors pod restart counts, analyzes logs, and executes remediation actions to restore service health.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: All Phase 1-4 notebooks\n",
    "- Inference pipeline deployed and running\n",
    "- Coordination engine accessible\n",
    "- OpenShift cluster with monitoring enabled\n",
    "\n",
    "## Learning Objectives\n",
    "- Detect pod crash loops automatically\n",
    "- Analyze container logs for root causes\n",
    "- Execute targeted remediation actions\n",
    "- Track healing success rates\n",
    "- Implement recovery workflows\n",
    "\n",
    "## Key Concepts\n",
    "- **Crash Loop**: Pod repeatedly crashing and restarting\n",
    "- **Restart Count**: Number of times pod has restarted\n",
    "- **Log Analysis**: Extract error patterns from logs\n",
    "- **Remediation**: Restart, scale, or update pod\n",
    "- **Success Tracking**: Monitor recovery outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport json\nimport logging\nimport subprocess\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\nimport re\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n        Path('/opt/app-root/src/openshift-aiops-platform/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    current = Path.cwd()\n    for _ in range(5):\n        utils_path = current / 'notebooks' / 'utils'\n        if utils_path.exists():\n            return str(utils_path)\n        current = current.parent\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"✅ Utils path found: {utils_path}\")\nelse:\n    print(\"⚠️ Utils path not found - will use fallback implementations\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import setup_environment\n    print(\"✅ Common functions imported\")\nexcept ImportError as e:\n    print(f\"⚠️ Common functions not available: {e}\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup environment\nenv_info = setup_environment()\nlogger.info(f\"Environment ready: {env_info}\")\n\n# Define paths\nDATA_DIR = Path('/opt/app-root/src/data')\nPROCESSED_DIR = DATA_DIR / 'processed'\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n\n# Configuration\nNAMESPACE = 'self-healing-platform'\nRESTART_THRESHOLD = 3  # Restart count threshold for crash loop\nLOG_LINES = 50  # Number of log lines to analyze\n\nlogger.info(f\"Pod crash loop healing initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Detect Crash Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_crash_loops(namespace, restart_threshold=3):\n",
    "    \"\"\"\n",
    "    Detect pods in crash loop by checking restart count.\n",
    "    \n",
    "    Args:\n",
    "        namespace: Kubernetes namespace\n",
    "        restart_threshold: Restart count threshold\n",
    "    \n",
    "    Returns:\n",
    "        List of pods in crash loop\n",
    "    \"\"\"\n",
    "    crash_loop_pods = []\n",
    "    \n",
    "    try:\n",
    "        # In real scenario, query Kubernetes API\n",
    "        # For demo, create sample data\n",
    "        sample_pods = [\n",
    "            {'name': 'app-pod-1', 'restart_count': 5, 'status': 'CrashLoopBackOff'},\n",
    "            {'name': 'app-pod-2', 'restart_count': 2, 'status': 'Running'},\n",
    "            {'name': 'app-pod-3', 'restart_count': 8, 'status': 'CrashLoopBackOff'},\n",
    "        ]\n",
    "        \n",
    "        for pod in sample_pods:\n",
    "            if pod['restart_count'] >= restart_threshold:\n",
    "                crash_loop_pods.append(pod)\n",
    "                logger.warning(f\"Crash loop detected: {pod['name']} (restarts: {pod['restart_count']})\")\n",
    "        \n",
    "        return crash_loop_pods\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error detecting crash loops: {e}\")\n",
    "        return []\n",
    "\n",
    "# Detect crash loops\n",
    "crash_loop_pods = detect_crash_loops(NAMESPACE, RESTART_THRESHOLD)\n",
    "logger.info(f\"Found {len(crash_loop_pods)} pods in crash loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyze Pod Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pod_logs(pod_name, namespace, lines=50):\n",
    "    \"\"\"\n",
    "    Analyze pod logs to identify root cause.\n",
    "    \n",
    "    Args:\n",
    "        pod_name: Pod name\n",
    "        namespace: Kubernetes namespace\n",
    "        lines: Number of log lines to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Log analysis result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sample error patterns\n",
    "        error_patterns = {\n",
    "            'OOMKilled': r'(OOMKilled|Out of memory)',\n",
    "            'CrashLoopBackOff': r'(CrashLoopBackOff|crash loop)',\n",
    "            'ImagePullBackOff': r'(ImagePullBackOff|Failed to pull image)',\n",
    "            'ConfigError': r'(ConfigError|configuration error)',\n",
    "            'HealthCheckFailed': r'(HealthCheckFailed|liveness probe failed)',\n",
    "        }\n",
    "        \n",
    "        # Sample logs\n",
    "        sample_logs = [\n",
    "            'ERROR: Connection refused to database',\n",
    "            'FATAL: Out of memory',\n",
    "            'ERROR: Failed to initialize service',\n",
    "        ]\n",
    "        \n",
    "        detected_errors = []\n",
    "        for error_type, pattern in error_patterns.items():\n",
    "            for log_line in sample_logs:\n",
    "                if re.search(pattern, log_line, re.IGNORECASE):\n",
    "                    detected_errors.append(error_type)\n",
    "        \n",
    "        analysis = {\n",
    "            'pod_name': pod_name,\n",
    "            'detected_errors': detected_errors if detected_errors else ['Unknown'],\n",
    "            'log_sample': sample_logs[:3],\n",
    "            'analysis_time': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Log analysis for {pod_name}: {analysis['detected_errors']}\")\n",
    "        return analysis\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error analyzing logs: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Analyze logs for crash loop pods\n",
    "log_analyses = []\n",
    "for pod in crash_loop_pods:\n",
    "    analysis = analyze_pod_logs(pod['name'], NAMESPACE, LOG_LINES)\n",
    "    log_analyses.append(analysis)\n",
    "\n",
    "logger.info(f\"Analyzed logs for {len(log_analyses)} pods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execute Remediation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_remediation(pod_name, namespace, error_type):\n",
    "    \"\"\"\n",
    "    Execute remediation action based on error type.\n",
    "    \n",
    "    Args:\n",
    "        pod_name: Pod name\n",
    "        namespace: Kubernetes namespace\n",
    "        error_type: Type of error detected\n",
    "    \n",
    "    Returns:\n",
    "        Remediation result\n",
    "    \"\"\"\n",
    "    remediation_actions = {\n",
    "        'OOMKilled': {\n",
    "            'action': 'scale_resources',\n",
    "            'command': f'oc set resources pod {pod_name} -n {namespace} --limits=memory=2Gi'\n",
    "        },\n",
    "        'CrashLoopBackOff': {\n",
    "            'action': 'restart_pod',\n",
    "            'command': f'oc delete pod {pod_name} -n {namespace}'\n",
    "        },\n",
    "        'ImagePullBackOff': {\n",
    "            'action': 'update_image',\n",
    "            'command': f'oc set image pod {pod_name} -n {namespace}'\n",
    "        },\n",
    "        'ConfigError': {\n",
    "            'action': 'update_config',\n",
    "            'command': f'oc rollout restart deployment -n {namespace}'\n",
    "        },\n",
    "        'HealthCheckFailed': {\n",
    "            'action': 'restart_pod',\n",
    "            'command': f'oc delete pod {pod_name} -n {namespace}'\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        action_config = remediation_actions.get(error_type, remediation_actions['CrashLoopBackOff'])\n",
    "        \n",
    "        logger.info(f\"Executing {action_config['action']} for {pod_name}\")\n",
    "        # In real scenario: subprocess.run(action_config['command'], shell=True)\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'pod_name': pod_name,\n",
    "            'action': action_config['action'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Remediation error: {e}\")\n",
    "        return {'success': False, 'error': str(e)}\n",
    "\n",
    "# Execute remediation\n",
    "remediation_results = []\n",
    "for analysis in log_analyses:\n",
    "    error_type = analysis['detected_errors'][0]\n",
    "    result = execute_remediation(analysis['pod_name'], NAMESPACE, error_type)\n",
    "    remediation_results.append(result)\n",
    "\n",
    "logger.info(f\"Executed remediation for {len(remediation_results)} pods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Track Healing Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create healing tracking dataframe\n",
    "healing_tracking = pd.DataFrame([\n",
    "    {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'pod_name': result['pod_name'],\n",
    "        'error_type': log_analyses[i]['detected_errors'][0],\n",
    "        'remediation_action': result['action'],\n",
    "        'success': result['success'],\n",
    "        'recovery_time_seconds': np.random.randint(5, 30),\n",
    "        'status': 'Running' if result['success'] else 'Failed'\n",
    "    }\n",
    "    for i, result in enumerate(remediation_results)\n",
    "])\n",
    "\n",
    "# Save tracking data\n",
    "tracking_file = PROCESSED_DIR / 'pod_crash_loop_healing.parquet'\n",
    "healing_tracking.to_parquet(tracking_file)\n",
    "\n",
    "logger.info(f\"Saved healing tracking data\")\n",
    "print(healing_tracking.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "assert len(crash_loop_pods) > 0, \"No crash loop pods detected\"\n",
    "assert len(log_analyses) > 0, \"No log analyses performed\"\n",
    "assert len(remediation_results) > 0, \"No remediation executed\"\n",
    "assert tracking_file.exists(), \"Healing tracking file not created\"\n",
    "\n",
    "success_rate = healing_tracking['success'].sum() / len(healing_tracking)\n",
    "logger.info(f\"✅ All validations passed\")\n",
    "print(f\"\\nPod Crash Loop Healing Summary:\")\n",
    "print(f\"  Crash Loop Pods Detected: {len(crash_loop_pods)}\")\n",
    "print(f\"  Remediation Actions Executed: {len(remediation_results)}\")\n",
    "print(f\"  Success Rate: {success_rate:.1%}\")\n",
    "print(f\"  Average Recovery Time: {healing_tracking['recovery_time_seconds'].mean():.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Inference pipeline predictions and pod metrics\n",
    "- **Output**: Healing tracking and recovery metrics\n",
    "- **Monitoring**: Prometheus for pod health metrics\n",
    "- **Next**: Resource exhaustion detection\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Monitor pod recovery status\n",
    "2. Proceed to `resource-exhaustion-detection.ipynb`\n",
    "3. Implement resource scaling workflows\n",
    "4. Test complete end-to-end scenarios\n",
    "5. Validate healing success rates\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-003: Self-Healing Platform Architecture\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [Kubernetes Pod Lifecycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)\n",
    "- [OpenShift Debugging Pods](https://docs.openshift.com/container-platform/latest/support/troubleshooting/investigating-pod-issues.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
