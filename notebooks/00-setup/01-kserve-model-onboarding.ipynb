{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KServe Model Onboarding\n",
        "\n",
        "## Welcome to the Self-Healing Platform ML Integration!\n",
        "\n",
        "This notebook guides you through using KServe models via the Coordination Engine.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "1. **Connect** to the Coordination Engine\n",
        "2. **Discover** available KServe models\n",
        "3. **Call** models for predictions\n",
        "4. **Add** custom models (no code changes needed!)\n",
        "\n",
        "### Architecture Overview\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  Notebook   â”‚â”€â”€â”€â”€â–¶â”‚ Coordination Engine  â”‚â”€â”€â”€â”€â–¶â”‚ KServe Inference    â”‚\n",
        "â”‚  (You!)     â”‚     â”‚ /api/v1/detect       â”‚     â”‚ Services            â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "**Benefits:**\n",
        "- âœ… Central orchestration for all ML models\n",
        "- âœ… Config-driven model registration\n",
        "- âœ… No code changes to add new models\n",
        "- âœ… GitOps-native workflow\n",
        "\n",
        "---\n",
        "\n",
        "**Reference:** ADR-039, ADR-040, [GitHub Issue #18](https://github.com/tosin2013/openshift-coordination-engine/issues/18)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "First, ensure you have the required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (if not already installed)\n",
        "import sys\n",
        "!{sys.executable} -m pip install requests pandas numpy --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import the Coordination Engine Client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Add the utils directory to the path\n",
        "sys.path.insert(0, '../utils')\n",
        "\n",
        "# Import the coordination engine client\n",
        "from coordination_engine_client import (\n",
        "    CoordinationEngineClient,\n",
        "    DetectResponse,\n",
        "    ModelHealth,\n",
        "    get_client\n",
        ")\n",
        "\n",
        "print(\"âœ… Coordination Engine Client imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Connect to the Coordination Engine\n",
        "\n",
        "The client automatically discovers the coordination engine URL from:\n",
        "1. `COORDINATION_ENGINE_URL` environment variable\n",
        "2. Default: `http://coordination-engine:8080`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a client instance\n",
        "client = get_client()\n",
        "print(f\"ğŸ“¡ Connected to: {client.base_url}\")\n",
        "\n",
        "# Verify connection with health check\n",
        "try:\n",
        "    health = client.health_check()\n",
        "    print(f\"âœ… Coordination Engine is healthy!\")\n",
        "    print(f\"   Version: {health.get('version', 'unknown')}\")\n",
        "    print(f\"   Status: {health.get('status', 'unknown')}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Could not connect: {e}\")\n",
        "    print(\"   Make sure the coordination engine is running.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Discover Available Models\n",
        "\n",
        "Let's see what KServe models are registered with the coordination engine:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all registered models\n",
        "try:\n",
        "    models = client.list_models()\n",
        "    model_count = client.get_model_count()\n",
        "    \n",
        "    print(f\"ğŸ“Š Found {model_count} registered model(s):\")\n",
        "    print(\"â”€\" * 40)\n",
        "    \n",
        "    for i, model in enumerate(models, 1):\n",
        "        print(f\"   {i}. {model}\")\n",
        "    \n",
        "    if not models:\n",
        "        print(\"   No models registered yet.\")\n",
        "        print(\"   See 'Adding Custom Models' section below.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error listing models: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Make Predictions\n",
        "\n",
        "Now let's call a model for predictions! The coordination engine supports the KServe v1 protocol.\n",
        "\n",
        "### Prediction Format\n",
        "\n",
        "**Request:**\n",
        "```json\n",
        "{\n",
        "  \"model\": \"anomaly-detector\",\n",
        "  \"instances\": [[0.5, 1.2, 0.8], [0.3, 0.9, 1.1]]\n",
        "}\n",
        "```\n",
        "\n",
        "**Response:**\n",
        "```json\n",
        "{\n",
        "  \"predictions\": [-1, 1],\n",
        "  \"model_name\": \"anomaly-detector\",\n",
        "  \"model_version\": \"v1\"\n",
        "}\n",
        "```\n",
        "\n",
        "- `predictions`: `-1` = anomaly detected, `1` = normal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Call the anomaly detector model\n",
        "MODEL_NAME = \"anomaly-detector\"  # Change this to your model\n",
        "\n",
        "# Sample data - replace with your actual feature vectors\n",
        "sample_instances = [\n",
        "    [0.5, 1.2, 0.8],   # Example: normal behavior\n",
        "    [0.3, 0.9, 1.1],   # Example: normal behavior\n",
        "    [2.5, 3.0, 4.0],   # Example: anomalous behavior\n",
        "    [0.4, 1.0, 0.9],   # Example: normal behavior\n",
        "    [5.0, 6.0, 7.0],   # Example: anomalous behavior\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Make prediction\n",
        "    result = client.detect_anomaly(\n",
        "        model_name=MODEL_NAME,\n",
        "        instances=sample_instances\n",
        "    )\n",
        "    \n",
        "    print(f\"ğŸ”® Predictions from '{result.model_name}':\")\n",
        "    print(\"â”€\" * 50)\n",
        "    \n",
        "    for i, (instance, pred) in enumerate(zip(sample_instances, result.predictions)):\n",
        "        status = \"ğŸ”´ ANOMALY\" if pred == -1 else \"ğŸŸ¢ Normal\"\n",
        "        print(f\"   Instance {i+1}: {instance} â†’ {status}\")\n",
        "    \n",
        "    print(\"â”€\" * 50)\n",
        "    print(f\"ğŸ“Š Summary:\")\n",
        "    print(f\"   Total instances: {len(result.predictions)}\")\n",
        "    print(f\"   Anomalies found: {result.anomaly_count()}\")\n",
        "    print(f\"   Anomaly rate: {result.anomaly_rate():.1%}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Prediction failed: {e}\")\n",
        "    print(\"\\nğŸ’¡ Tips:\")\n",
        "    print(f\"   - Check if model '{MODEL_NAME}' is registered\")\n",
        "    print(\"   - Verify the model service is healthy\")\n",
        "    print(\"   - Check your feature vector format\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Adding Custom Models (No Code Changes!)\n",
        "\n",
        "The coordination engine supports dynamic model discovery. You can add custom models by simply updating `values-hub.yaml`.\n",
        "\n",
        "### How It Works\n",
        "\n",
        "1. **Deploy your KServe InferenceService**\n",
        "2. **Update values-hub.yaml** to register the model\n",
        "3. **Sync with ArgoCD** - model is automatically available!\n",
        "\n",
        "### Example: Adding a Disk Failure Predictor\n",
        "\n",
        "**1. Deploy the InferenceService:**\n",
        "\n",
        "```yaml\n",
        "apiVersion: serving.kserve.io/v1beta1\n",
        "kind: InferenceService\n",
        "metadata:\n",
        "  name: disk-failure-predictor\n",
        "  namespace: self-healing-platform\n",
        "spec:\n",
        "  predictor:\n",
        "    model:\n",
        "      modelFormat:\n",
        "        name: sklearn\n",
        "      storageUri: \"pvc://model-storage-pvc/disk-failure-predictor\"\n",
        "```\n",
        "\n",
        "**2. Register in values-hub.yaml:**\n",
        "\n",
        "```yaml\n",
        "coordinationEngine:\n",
        "  kserve:\n",
        "    enabled: true\n",
        "    namespace: self-healing-platform\n",
        "    services:\n",
        "      anomaly_detector: \"anomaly-detector-predictor\"\n",
        "      predictive_analytics: \"predictive-analytics-predictor\"\n",
        "      # ADD YOUR CUSTOM MODEL HERE:\n",
        "      disk_failure_predictor: \"disk-failure-predictor-predictor\"\n",
        "```\n",
        "\n",
        "**3. Use from notebook:**\n",
        "\n",
        "```python\n",
        "result = client.detect_anomaly(\n",
        "    model_name=\"disk-failure-predictor\",\n",
        "    instances=[[85.5, 5000, 365]]  # disk_usage, io_count, age_days\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‰ Congratulations!\n",
        "\n",
        "You've completed the KServe Model Onboarding tutorial. You now know how to:\n",
        "\n",
        "- âœ… Connect to the Coordination Engine\n",
        "- âœ… Discover available models\n",
        "- âœ… Make predictions via the KServe proxy\n",
        "- âœ… Add custom models without code changes\n",
        "\n",
        "### Quick Reference\n",
        "\n",
        "```python\n",
        "from utils.coordination_engine_client import get_client\n",
        "\n",
        "client = get_client()\n",
        "models = client.list_models()\n",
        "result = client.detect_anomaly(\"model-name\", [[features...]])\n",
        "health = client.check_model_health(\"model-name\")\n",
        "```\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Explore other notebooks:**\n",
        "   - `02-anomaly-detection/` - Train your own models\n",
        "   - `03-self-healing-logic/` - Integrate with remediation workflows\n",
        "   - `04-model-serving/` - Deploy models to KServe\n",
        "\n",
        "2. **Contribute!** Open issues or PRs at:\n",
        "   - [Coordination Engine](https://github.com/tosin2013/openshift-coordination-engine)\n",
        "   - [AIOps Platform](https://github.com/tosin2013/openshift-aiops-platform)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
