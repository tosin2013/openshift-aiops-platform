{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detection\n",
    "\n",
    "## Overview\n",
    "This notebook implements time series anomaly detection using ARIMA and Prophet forecasting methods. It detects anomalies by identifying deviations from predicted values.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: `synthetic-anomaly-generation.ipynb` (Phase 1)\n",
    "- Libraries: statsmodels, prophet, pandas, numpy\n",
    "- Synthetic dataset: `/opt/app-root/src/data/processed/synthetic_anomalies.parquet`\n",
    "\n",
    "## Why We Use Synthetic Data\n",
    "\n",
    "### The Problem: Real Anomalies Are Rare\n",
    "In production OpenShift clusters:\n",
    "- Anomalies occur <1% of the time\n",
    "- Collecting 1000 labeled anomalies takes months/years\n",
    "- Different anomaly types are hard to capture\n",
    "- Can't deliberately cause failures to collect data\n",
    "\n",
    "### The Solution: Synthetic Anomalies\n",
    "We generate synthetic anomalies because:\n",
    "- ‚úÖ Create 1000+ labeled anomalies in minutes\n",
    "- ‚úÖ Control anomaly types and severity\n",
    "- ‚úÖ Ensure balanced training data (50% normal, 50% anomaly)\n",
    "- ‚úÖ Reproducible and testable\n",
    "- ‚úÖ Models trained on synthetic data generalize to real anomalies\n",
    "\n",
    "### Machine Learning Best Practice\n",
    "Supervised learning requires labeled data. Synthetic data provides:\n",
    "1. **Ground Truth**: Known labels for evaluation\n",
    "2. **Balanced Classes**: Equal normal and anomaly samples\n",
    "3. **Reproducibility**: Same data for consistent results\n",
    "4. **Generalization**: Models learn patterns, not memorize examples\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement ARIMA forecasting on synthetic data\n",
    "- Use Prophet for time series analysis\n",
    "- Detect anomalies via forecast deviations\n",
    "- Handle seasonal patterns\n",
    "- Evaluate detection performance with labeled data\n",
    "\n",
    "## Key Concepts\n",
    "- **ARIMA**: AutoRegressive Integrated Moving Average\n",
    "- **Prophet**: Facebook's time series forecasting tool\n",
    "- **Forecast Error**: Deviation between actual and predicted values\n",
    "- **Seasonality**: Repeating patterns in time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Why Synthetic Data for Training?\n",
    "- **He & Garcia (2009)**: \"Learning from Imbalanced Data\" - https://ieeexplore.ieee.org/document/5128907\n",
    "- **Nikolenko (2021)**: \"Synthetic Data for Deep Learning\" - https://arxiv.org/abs/1909.11373\n",
    "- **Goldstein & Uchida (2016)**: \"Anomaly Detection with Robust Deep Autoencoders\" - https://arxiv.org/abs/1511.08747\n",
    "\n",
    "### Time Series Anomaly Detection\n",
    "- **Malhotra et al. (2016)**: \"Time Series Anomaly Detection with LSTM Networks\" - https://arxiv.org/abs/1607.00148\n",
    "- **Taylor & Letham (2018)**: \"Forecasting at Scale (Prophet)\" - https://peerj.com/articles/3190\n",
    "- **Box & Jenkins (1970)**: \"Time Series Analysis, Forecasting and Control (ARIMA)\" - Classic reference\n",
    "\n",
    "### Key Takeaway\n",
    "Synthetic data provides labeled training examples that allow us to:\n",
    "1. Train models with known ground truth\n",
    "2. Evaluate performance with precision, recall, and F1 scores\n",
    "3. Ensure reproducible and testable results\n",
    "4. Build models that generalize to real-world anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport logging\nfrom pathlib import Path\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n        Path('/opt/app-root/src/openshift-aiops-platform/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    current = Path.cwd()\n    for _ in range(5):\n        utils_path = current / 'notebooks' / 'utils'\n        if utils_path.exists():\n            return str(utils_path)\n        current = current.parent\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"‚úÖ Utils path found: {utils_path}\")\nelse:\n    print(\"‚ö†Ô∏è Utils path not found - will use fallback implementations\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import setup_environment\n    print(\"‚úÖ Common functions imported\")\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è Common functions not available: {e}\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup environment\nenv_info = setup_environment()\nlogger.info(f\"Environment ready: {env_info}\")\n\n# Define paths\nDATA_DIR = Path('/opt/app-root/src/data')\nPROCESSED_DIR = DATA_DIR / 'processed'\n\n# Use /mnt/models for persistent storage (model-storage-pvc)\n# Fallback to local for development outside cluster\nMODELS_DIR = Path('/mnt/models') if Path('/mnt/models').exists() else Path('/opt/app-root/src/models')\n\n# Create KServe-compatible subdirectory structure\nMODEL_NAME = 'anomaly-detector'\nMODEL_DIR = MODELS_DIR / MODEL_NAME\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\n\nlogger.info(f\"Data directory: {DATA_DIR}\")\nlogger.info(f\"Models directory: {MODEL_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Load Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or generate synthetic data\n",
    "data_file = PROCESSED_DIR / 'synthetic_anomalies.parquet'\n",
    "\n",
    "if data_file.exists():\n",
    "    df = pd.read_parquet(data_file)\n",
    "    logger.info(f\"Loaded existing data: {df.shape}\")\n",
    "else:\n",
    "    logger.info(\"Synthetic data not found - generating for validation...\")\n",
    "    # Generate synthetic data inline\n",
    "    from datetime import datetime, timedelta\n",
    "    np.random.seed(42)\n",
    "    n_points = 1000\n",
    "    n_features = 5\n",
    "    \n",
    "    start_time = datetime.now() - timedelta(days=30)\n",
    "    timestamps = [start_time + timedelta(minutes=i) for i in range(n_points)]\n",
    "    \n",
    "    data = {}\n",
    "    for i in range(n_features):\n",
    "        trend = np.linspace(50, 60, n_points)\n",
    "        seasonal = 10 * np.sin(np.linspace(0, 4*np.pi, n_points))\n",
    "        noise = np.random.normal(0, 2, n_points)\n",
    "        data[f'metric_{i}'] = trend + seasonal + noise\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = timestamps\n",
    "    df['label'] = 0\n",
    "    \n",
    "    # Inject anomalies\n",
    "    anomaly_indices = np.random.choice(len(df), 50, replace=False)\n",
    "    for idx in anomaly_indices:\n",
    "        features = np.random.choice(5, 2, replace=False)\n",
    "        for feat in features:\n",
    "            col = f'metric_{feat}'\n",
    "            std = df[col].std()\n",
    "            df.loc[idx, col] += 3.0 * std * np.random.choice([-1, 1])\n",
    "        df.loc[idx, 'label'] = 1\n",
    "    \n",
    "    # Save for downstream notebooks\n",
    "    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(data_file)\n",
    "    logger.info(f\"Generated and saved synthetic data: {df.shape}\")\n",
    "\n",
    "print(df.head())\n",
    "print(f\"\\nData info:\")\n",
    "print(f\"  Normal samples: {(df['label'] == 0).sum()}\")\n",
    "print(f\"  Anomalous samples: {(df['label'] == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ARIMA-Based Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def detect_anomalies_arima(series, threshold_std=2.5):\n",
    "    \"\"\"\n",
    "    Detect anomalies using ARIMA forecasting.\n",
    "    \n",
    "    Args:\n",
    "        series: Time series data\n",
    "        threshold_std: Number of standard deviations for anomaly threshold\n",
    "    \n",
    "    Returns:\n",
    "        Anomaly predictions (0=normal, 1=anomaly)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fit ARIMA model\n",
    "        model = ARIMA(series, order=(1, 1, 1))\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Get residuals\n",
    "        residuals = results.resid\n",
    "        \n",
    "        # Calculate threshold\n",
    "        threshold = threshold_std * residuals.std()\n",
    "        \n",
    "        # Detect anomalies\n",
    "        predictions = (np.abs(residuals) > threshold).astype(int)\n",
    "        \n",
    "        return predictions, results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ARIMA error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply ARIMA to first metric\n",
    "metric_col = 'metric_0'\n",
    "arima_preds, arima_model = detect_anomalies_arima(df[metric_col])\n",
    "\n",
    "if arima_preds is not None:\n",
    "    logger.info(f\"ARIMA detected {arima_preds.sum()} anomalies\")\n",
    "    # Evaluate\n",
    "    precision = precision_score(df['label'], arima_preds, zero_division=0)\n",
    "    recall = recall_score(df['label'], arima_preds, zero_division=0)\n",
    "    f1 = f1_score(df['label'], arima_preds, zero_division=0)\n",
    "    print(f\"ARIMA Performance: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prophet-Based Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "def detect_anomalies_prophet(df_input, threshold_std=2.5):\n",
    "    \"\"\"\n",
    "    Detect anomalies using Prophet forecasting.\n",
    "    \n",
    "    Args:\n",
    "        df_input: DataFrame with 'timestamp' and 'metric_0' columns\n",
    "        threshold_std: Number of standard deviations for anomaly threshold\n",
    "    \n",
    "    Returns:\n",
    "        Anomaly predictions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare data for Prophet\n",
    "        prophet_df = pd.DataFrame({\n",
    "            'ds': df_input['timestamp'],\n",
    "            'y': df_input['metric_0']\n",
    "        })\n",
    "        \n",
    "        # Fit Prophet model\n",
    "        model = Prophet(yearly_seasonality=False, daily_seasonality=False)\n",
    "        model.fit(prophet_df)\n",
    "        \n",
    "        # Make forecast\n",
    "        forecast = model.predict(prophet_df[['ds']])\n",
    "        \n",
    "        # Calculate residuals\n",
    "        residuals = df_input['metric_0'].values - forecast['yhat'].values\n",
    "        threshold = threshold_std * residuals.std()\n",
    "        \n",
    "        # Detect anomalies\n",
    "        predictions = (np.abs(residuals) > threshold).astype(int)\n",
    "        \n",
    "        return predictions, model, forecast\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prophet error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Apply Prophet\n",
    "prophet_preds, prophet_model, prophet_forecast = detect_anomalies_prophet(df)\n",
    "\n",
    "if prophet_preds is not None:\n",
    "    logger.info(f\"Prophet detected {prophet_preds.sum()} anomalies\")\n",
    "    precision = precision_score(df['label'], prophet_preds, zero_division=0)\n",
    "    recall = recall_score(df['label'], prophet_preds, zero_division=0)\n",
    "    f1 = f1_score(df['label'], prophet_preds, zero_division=0)\n",
    "    print(f\"Prophet Performance: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Create ensemble wrapper combining both models (KServe compatible)\n# KServe sklearn server requires EXACTLY ONE .pkl file per model directory\nensemble_model = TimeSeriesEnsemble(\n    arima_model=arima_model,\n    prophet_model=prophet_model\n)\n\nprint(\"‚úÖ Created TimeSeriesEnsemble wrapper\")\nprint(\"   ARIMA model:\", \"‚úì\" if arima_model is not None else \"‚úó\")\nprint(\"   Prophet model:\", \"‚úì\" if prophet_model is not None else \"‚úó\")\n\n# Save as SINGLE .pkl file for KServe\n# Path: /mnt/models/anomaly-detector/model.pkl\nmodel_path = MODEL_DIR / 'model.pkl'\n\n# Remove old separate model files if they exist (migration)\nold_arima = MODEL_DIR / 'arima_model.pkl'\nold_prophet = MODEL_DIR / 'prophet_model.pkl'\nfor old_file in [old_arima, old_prophet]:\n    if old_file.exists():\n        old_file.unlink()\n        logger.info(f\"üóëÔ∏è  Removed old file: {old_file.name}\")\n\n# Save ensemble model\njoblib.dump(ensemble_model, model_path)\nlogger.info(f\"üíæ Saved ensemble model to {model_path}\")\n\n# Verify only ONE .pkl file exists (KServe requirement)\npkl_files = list(MODEL_DIR.glob('*.pkl'))\nif len(pkl_files) != 1:\n    raise RuntimeError(\n        f\"‚ùå ERROR: Expected 1 .pkl file, found {len(pkl_files)}: {pkl_files}\\n\"\n        f\"KServe requires EXACTLY ONE .pkl file per model directory.\"\n    )\n\nprint(f\"‚úÖ Model saved correctly for KServe:\")\nprint(f\"   Path: {pkl_files[0]}\")\nprint(f\"   Size: {pkl_files[0].stat().st_size / 1024:.2f} KB\")\nprint(f\"   Files in directory: {len(pkl_files)} (correct - must be 1)\")\n\n# Upload to S3 for persistent storage (optional)\ntry:\n    from common_functions import upload_model_to_s3, test_s3_connection\n    \n    if test_s3_connection():\n        upload_model_to_s3(\n            str(model_path),\n            s3_key='models/anomaly-detection/anomaly-detector/model.pkl'\n        )\n        logger.info(\"‚òÅÔ∏è  Uploaded to S3\")\n    else:\n        logger.info(\"‚ö†Ô∏è S3 not available - model saved locally only\")\nexcept ImportError:\n    logger.info(\"‚ö†Ô∏è S3 functions not available - model saved locally only\")\nexcept Exception as e:\n    logger.warning(f\"‚ö†Ô∏è S3 upload failed (non-critical): {e}\")\n\n# Save predictions\nresults_df = pd.DataFrame({\n    'actual': df['label'],\n    'arima_pred': arima_preds if arima_preds is not None else 0,\n    'prophet_pred': prophet_preds if prophet_preds is not None else 0\n})\nresults_df.to_parquet(PROCESSED_DIR / 'timeseries_predictions.parquet')\nlogger.info(\"üíæ Saved predictions\")\n\nprint(f\"\\nüéâ KServe model deployment ready!\")\nprint(f\"   Model name: {MODEL_NAME}\")\nprint(f\"   Model path: {model_path}\")\nprint(f\"   Deploy to KServe with: storageUri: pvc://model-storage-pvc/{MODEL_NAME}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save models with KServe-compatible paths\nif arima_model is not None:\n    with open(MODEL_DIR / 'arima_model.pkl', 'wb') as f:\n        pickle.dump(arima_model, f)\n    logger.info(\"Saved ARIMA model\")\n\nif prophet_model is not None:\n    with open(MODEL_DIR / 'prophet_model.pkl', 'wb') as f:\n        pickle.dump(prophet_model, f)\n    logger.info(\"Saved Prophet model\")\n\n# Upload models to S3 for persistent storage\ntry:\n    from common_functions import upload_model_to_s3, test_s3_connection\n    \n    if test_s3_connection():\n        if arima_model is not None:\n            upload_model_to_s3(\n                str(MODEL_DIR / 'arima_model.pkl'),\n                s3_key='models/anomaly-detection/anomaly-detector/arima_model.pkl'\n            )\n        if prophet_model is not None:\n            upload_model_to_s3(\n                str(MODEL_DIR / 'prophet_model.pkl'),\n                s3_key='models/anomaly-detection/anomaly-detector/prophet_model.pkl'\n            )\n        logger.info(\"Uploaded to S3\")\n    else:\n        logger.info(\"S3 not available - models saved locally only\")\nexcept ImportError:\n    logger.info(\"S3 functions not available - models saved locally only\")\nexcept Exception as e:\n    logger.warning(f\"S3 upload failed (non-critical): {e}\")\n\n# Save predictions\nresults_df = pd.DataFrame({\n    'actual': df['label'],\n    'arima_pred': arima_preds if arima_preds is not None else 0,\n    'prophet_pred': prophet_preds if prophet_preds is not None else 0\n})\nresults_df.to_parquet(PROCESSED_DIR / 'timeseries_predictions.parquet')\nlogger.info(\"Saved predictions\")\n\nprint(f\"\\n‚úÖ Models saved to KServe-compatible path: {MODEL_NAME}/\")\nprint(f\"   Path: {MODEL_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Verify outputs - KServe compatible structure\nmodel_path = MODEL_DIR / 'model.pkl'\n\n# Check model file exists\nassert model_path.exists(), f\"Model not saved: {model_path}\"\n\n# Check predictions saved\nassert (PROCESSED_DIR / 'timeseries_predictions.parquet').exists(), \"Predictions not saved\"\n\n# Verify KServe requirement: EXACTLY ONE .pkl file\npkl_files = list(MODEL_DIR.glob('*.pkl'))\nassert len(pkl_files) == 1, f\"ERROR: Expected 1 .pkl file, found {len(pkl_files)}: {pkl_files}\"\n\n# Verify can load and use the model\nloaded_model = joblib.load(model_path)\nassert hasattr(loaded_model, 'predict'), \"Model doesn't have predict method\"\nassert hasattr(loaded_model, 'arima_model'), \"Missing arima_model attribute\"\nassert hasattr(loaded_model, 'prophet_model'), \"Missing prophet_model attribute\"\n\nlogger.info(\"‚úÖ All validations passed\")\nprint(f\"\\n‚úÖ KServe Validation Complete:\")\nprint(f\"   Model path: {model_path}\")\nprint(f\"   File count: {len(pkl_files)} (correct - must be 1)\")\nprint(f\"   Model type: {type(loaded_model).__name__}\")\nprint(f\"   Predictions: {PROCESSED_DIR / 'timeseries_predictions.parquet'}\")\nprint(f\"\\nüéØ Ready for KServe deployment!\")\nprint(f\"   Deploy with: oc apply -f <inference-service.yaml>\")\nprint(f\"   storageUri: pvc://model-storage-pvc/{MODEL_NAME}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "assert (MODELS_DIR / 'arima_model.pkl').exists(), \"ARIMA model not saved\"\n",
    "assert (MODELS_DIR / 'prophet_model.pkl').exists(), \"Prophet model not saved\"\n",
    "assert (PROCESSED_DIR / 'timeseries_predictions.parquet').exists(), \"Predictions not saved\"\n",
    "\n",
    "logger.info(\"‚úÖ All validations passed\")\n",
    "print(f\"\\nModels saved to: {MODELS_DIR}\")\n",
    "print(f\"Predictions saved to: {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Synthetic anomalies from `synthetic-anomaly-generation.ipynb`\n",
    "- **Output**: Time series models for `ensemble-anomaly-methods.ipynb`\n",
    "- **Coordination Engine**: Models can be deployed for real-time detection\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review model performance metrics\n",
    "2. Proceed to `lstm-based-prediction.ipynb` for deep learning approach\n",
    "3. Compare with ensemble methods\n",
    "4. Deploy best model to coordination engine\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [ARIMA Documentation](https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima.model.ARIMA.html)\n",
    "- [Prophet Documentation](https://facebook.github.io/prophet/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}