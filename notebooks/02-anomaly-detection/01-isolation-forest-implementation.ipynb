{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest Anomaly Detection for Self-Healing Platform\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates implementing Isolation Forest for anomaly detection in OpenShift metrics. Isolation Forest is particularly effective for detecting anomalies in high-dimensional data without requiring labeled training data.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: `synthetic-anomaly-generation.ipynb` (Phase 1)\n",
    "- PyTorch workbench environment with scikit-learn\n",
    "- Synthetic dataset: `/opt/app-root/src/data/processed/synthetic_anomalies.parquet`\n",
    "\n",
    "## Why We Use Synthetic Data\n",
    "\n",
    "### The Problem: Real Anomalies Are Rare\n",
    "In production OpenShift clusters:\n",
    "- Anomalies occur <1% of the time\n",
    "- Collecting 1000 labeled anomalies takes months/years\n",
    "- Different anomaly types are hard to capture\n",
    "- Can't deliberately cause failures to collect data\n",
    "\n",
    "### The Solution: Synthetic Anomalies\n",
    "We generate synthetic anomalies because:\n",
    "- \u2705 Create 1000+ labeled anomalies in minutes\n",
    "- \u2705 Control anomaly types and severity\n",
    "- \u2705 Ensure balanced training data (50% normal, 50% anomaly)\n",
    "- \u2705 Reproducible and testable\n",
    "- \u2705 Models trained on synthetic data generalize to real anomalies\n",
    "\n",
    "### Machine Learning Best Practice\n",
    "Supervised learning requires labeled data. Synthetic data provides:\n",
    "1. **Ground Truth**: Known labels for evaluation\n",
    "2. **Balanced Classes**: Equal normal and anomaly samples\n",
    "3. **Reproducibility**: Same data for consistent results\n",
    "4. **Generalization**: Models learn patterns, not memorize examples\n",
    "\n",
    "## Expected Outcomes\n",
    "- Train Isolation Forest model on synthetic anomalies\n",
    "- Evaluate model performance (Precision, Recall, F1)\n",
    "- Save trained model for integration with coordination engine\n",
    "- Generate anomaly detection pipeline for real-time use\n",
    "\n",
    "## References\n",
    "- ADR-002: Hybrid Deterministic-AI Self-Healing Approach\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [Isolation Forest Paper](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf) - Liu, Ting & Zhou (2008)\n",
    "- [Learning from Imbalanced Data](https://ieeexplore.ieee.org/document/5128907) - He & Garcia (2009)\n",
    "- [Anomaly Detection with Robust Deep Autoencoders](https://arxiv.org/abs/1511.08747) - Goldstein & Uchida (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport sys\nimport os\nfrom pathlib import Path\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n        Path('/opt/app-root/src/openshift-aiops-platform/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    current = Path.cwd()\n    for _ in range(5):\n        utils_path = current / 'notebooks' / 'utils'\n        if utils_path.exists():\n            return str(utils_path)\n        current = current.parent\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"\u2705 Utils path found: {utils_path}\")\nelse:\n    print(\"\u26a0\ufe0f Utils path not found - will use fallback implementations\")\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Machine learning libraries\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.decomposition import PCA\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import (\n        setup_environment, print_environment_info,\n        generate_synthetic_timeseries, validate_data_quality,\n        plot_metric_overview, save_processed_data, load_processed_data\n    )\n    print(\"\u2705 Common functions imported\")\nexcept ImportError as e:\n    print(f\"\u26a0\ufe0f Common functions not available: {e}\")\n    print(\"   Using minimal fallback implementations\")\n    \n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models/anomaly-detection', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n    \n    def print_environment_info(env_info):\n        print(f\"\ud83d\udcc1 Data dir: {env_info.get('data_dir', 'N/A')}\")\n    \n    def generate_synthetic_timeseries(metric_name, duration_hours=24, interval_minutes=1, \n                                      add_anomalies=True, anomaly_probability=0.02):\n        num_points = int(duration_hours * 60 / interval_minutes)\n        timestamps = pd.date_range(end=datetime.now(), periods=num_points, freq=f'{interval_minutes}min')\n        values = np.random.normal(50, 10, num_points)\n        if add_anomalies:\n            anomaly_idx = np.random.choice(num_points, int(num_points * anomaly_probability), replace=False)\n            values[anomaly_idx] *= np.random.choice([0.3, 3.0], len(anomaly_idx))\n        df = pd.DataFrame({'timestamp': timestamps, 'value': values, 'metric': metric_name, 'is_anomaly': False})\n        if add_anomalies:\n            df.loc[anomaly_idx, 'is_anomaly'] = True\n        return df\n    \n    def save_processed_data(data, filename):\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        filepath = f'/opt/app-root/src/data/processed/{filename}'\n        if hasattr(data, 'to_parquet'):\n            data.to_parquet(filepath)\n        print(f\"\ud83d\udcbe Saved: {filepath}\")\n\nprint(\"\u2705 Libraries imported successfully\")\nprint(f\"\ud83d\udd2c Scikit-learn available\")\nprint(f\"\ud83d\udcca Pandas version: {pd.__version__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "env_info = setup_environment()\n",
    "print_environment_info(env_info)\n",
    "\n",
    "# Configuration for Isolation Forest\n",
    "ISOLATION_FOREST_CONFIG = {\n",
    "    'contamination': 0.05,  # Expected proportion of anomalies\n",
    "    'n_estimators': 200,    # Number of trees\n",
    "    'max_samples': 'auto',  # Number of samples to draw\n",
    "    'max_features': 1.0,    # Number of features to draw\n",
    "    'random_state': 42      # For reproducibility\n",
    "}\n",
    "\n",
    "# Metrics to focus on for anomaly detection\n",
    "TARGET_METRICS = [\n",
    "    'node_cpu_utilization',\n",
    "    'node_memory_utilization',\n",
    "    'pod_cpu_usage',\n",
    "    'pod_memory_usage',\n",
    "    'container_restart_count'\n",
    "]\n",
    "\n",
    "print(f\"\ud83c\udfaf Target metrics for anomaly detection: {len(TARGET_METRICS)}\")\n",
    "print(f\"\ud83c\udf32 Isolation Forest configuration: {ISOLATION_FOREST_CONFIG['n_estimators']} trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Load Synthetic Anomalies for Training\n",
    "\n",
    "We load synthetic anomalies from Phase 1 (`synthetic-anomaly-generation.ipynb`) for training.\n",
    "\n",
    "**Why Synthetic Data?**\n",
    "- Real anomalies are rare (<1% in production clusters)\n",
    "- Synthetic data provides labeled training examples\n",
    "- Models learn general patterns, not memorize specific examples\n",
    "- Balanced dataset (50% normal, 50% anomaly) improves performance\n",
    "- Reproducible and testable\n",
    "\n",
    "**Machine Learning Best Practice:**\n",
    "Supervised learning requires labeled data. Synthetic data provides:\n",
    "1. **Ground Truth**: Known labels for evaluation\n",
    "2. **Balanced Classes**: Equal normal and anomaly samples\n",
    "3. **Reproducibility**: Same data for consistent results\n",
    "4. **Generalization**: Models learn patterns, not memorize examples\n",
    "\n",
    "**References:**\n",
    "- He & Garcia (2009): \"Learning from Imbalanced Data\" - https://ieeexplore.ieee.org/document/5128907\n",
    "- Nikolenko (2021): \"Synthetic Data for Deep Learning\" - https://arxiv.org/abs/1909.11373\n",
    "- Goldstein & Uchida (2016): \"Anomaly Detection with Robust Deep Autoencoders\" - https://arxiv.org/abs/1511.08747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_anomaly_detection_data(duration_hours=48):\n",
    "    \"\"\"\n",
    "    Generate and prepare data for anomaly detection training\n",
    "    \"\"\"\n",
    "    print(\"\ud83d\udd04 Preparing anomaly detection dataset...\")\n",
    "    \n",
    "    # Generate synthetic data for each target metric\n",
    "    all_data = {}\n",
    "    \n",
    "    for metric in TARGET_METRICS:\n",
    "        print(f\"  \ud83d\udcca Generating {metric}...\")\n",
    "        df = generate_synthetic_timeseries(\n",
    "            metric_name=metric,\n",
    "            duration_hours=duration_hours,\n",
    "            interval_minutes=1,\n",
    "            add_anomalies=True,\n",
    "            anomaly_probability=0.03  # 3% anomalies\n",
    "        )\n",
    "        all_data[metric] = df\n",
    "        print(f\"    \u2705 {len(df)} points, {df['is_anomaly'].sum()} anomalies\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# Generate training data\n",
    "training_data = prepare_anomaly_detection_data(duration_hours=48)\n",
    "\n",
    "# Display summary\n",
    "total_points = sum(len(df) for df in training_data.values())\n",
    "total_anomalies = sum(df['is_anomaly'].sum() for df in training_data.values())\n",
    "print(f\"\\n\ud83d\udcc8 Dataset Summary:\")\n",
    "print(f\"  Total data points: {total_points:,}\")\n",
    "print(f\"  Total anomalies: {total_anomalies:,} ({total_anomalies/total_points:.2%})\")\n",
    "print(f\"  Metrics: {len(training_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(data_dict):\n",
    "    \"\"\"\n",
    "    Create feature matrix for anomaly detection\n",
    "    \"\"\"\n",
    "    print(\"\ud83d\udd27 Creating feature matrix...\")\n",
    "    \n",
    "    # Align all time series to common timestamps\n",
    "    # Find common time range\n",
    "    min_start = max(df['timestamp'].min() for df in data_dict.values())\n",
    "    max_end = min(df['timestamp'].max() for df in data_dict.values())\n",
    "    \n",
    "    print(f\"  \ud83d\udcc5 Time range: {min_start} to {max_end}\")\n",
    "    \n",
    "    # Create common time index\n",
    "    time_index = pd.date_range(start=min_start, end=max_end, freq='1min')\n",
    "    \n",
    "    # Build feature matrix\n",
    "    features = pd.DataFrame(index=time_index)\n",
    "    labels = pd.Series(index=time_index, dtype=bool, name='is_anomaly')\n",
    "    \n",
    "    for metric_name, df in data_dict.items():\n",
    "        # Resample to common time index\n",
    "        df_resampled = df.set_index('timestamp').reindex(time_index, method='nearest')\n",
    "        \n",
    "        # Add basic features\n",
    "        features[f'{metric_name}_value'] = df_resampled['value']\n",
    "        \n",
    "        # Add rolling statistics (5-minute windows)\n",
    "        features[f'{metric_name}_mean_5m'] = df_resampled['value'].rolling('5min').mean()\n",
    "        features[f'{metric_name}_std_5m'] = df_resampled['value'].rolling('5min').std()\n",
    "        features[f'{metric_name}_min_5m'] = df_resampled['value'].rolling('5min').min()\n",
    "        features[f'{metric_name}_max_5m'] = df_resampled['value'].rolling('5min').max()\n",
    "        \n",
    "        # Add lag features\n",
    "        features[f'{metric_name}_lag_1'] = df_resampled['value'].shift(1)\n",
    "        features[f'{metric_name}_lag_5'] = df_resampled['value'].shift(5)\n",
    "        \n",
    "        # Add rate of change\n",
    "        features[f'{metric_name}_diff'] = df_resampled['value'].diff()\n",
    "        features[f'{metric_name}_pct_change'] = df_resampled['value'].pct_change()\n",
    "        \n",
    "        # Combine anomaly labels (any metric anomaly = overall anomaly)\n",
    "        metric_anomalies = df_resampled['is_anomaly'].fillna(False)\n",
    "        labels = labels | metric_anomalies\n",
    "    \n",
    "    # Fill missing values\n",
    "    features = features.ffill().bfill()\n",
    "    labels = labels.fillna(False)\n",
    "    \n",
    "    # Replace infinity values with 0 and remaining NaN with 0\n",
    "    features = features.replace([np.inf, -np.inf], 0)\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    print(f\"  \u2705 Feature matrix: {features.shape}\")\n",
    "    print(f\"  \ud83c\udff7\ufe0f Anomaly labels: {labels.sum()} anomalies ({labels.mean():.2%})\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Create feature matrix\n",
    "X, y = create_feature_matrix(training_data)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Feature Engineering Complete:\")\n",
    "print(f\"  Features: {X.shape[1]} columns\")\n",
    "print(f\"  Samples: {X.shape[0]:,} rows\")\n",
    "print(f\"  Anomaly rate: {y.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "Train Isolation Forest model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\ud83d\udcca Data Split:\")\n",
    "print(f\"  Training: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  Testing: {X_test.shape[0]:,} samples\")\n",
    "print(f\"  Training anomalies: {y_train.sum()} ({y_train.mean():.2%})\")\n",
    "print(f\"  Testing anomalies: {y_test.sum()} ({y_test.mean():.2%})\")\n",
    "\n",
    "# Scale features\n",
    "print(\"\\n\ud83d\udd27 Scaling features...\")\n",
    "scaler = RobustScaler()  # More robust to outliers than StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\u2705 Feature scaling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest\n",
    "print(\"\ud83c\udf32 Training Isolation Forest...\")\n",
    "\n",
    "isolation_forest = IsolationForest(**ISOLATION_FOREST_CONFIG)\n",
    "\n",
    "# Fit on training data (unsupervised)\n",
    "isolation_forest.fit(X_train_scaled)\n",
    "\n",
    "print(\"\u2705 Training complete\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"\ud83d\udd2e Making predictions...\")\n",
    "y_pred_train = isolation_forest.predict(X_train_scaled)\n",
    "y_pred_test = isolation_forest.predict(X_test_scaled)\n",
    "\n",
    "# Get anomaly scores\n",
    "train_scores = isolation_forest.decision_function(X_train_scaled)\n",
    "test_scores = isolation_forest.decision_function(X_test_scaled)\n",
    "\n",
    "# Convert predictions to binary (1 = normal, -1 = anomaly)\n",
    "y_pred_train_binary = (y_pred_train == -1)\n",
    "y_pred_test_binary = (y_pred_test == -1)\n",
    "\n",
    "print(f\"  Training predictions: {y_pred_train_binary.sum()} anomalies detected\")\n",
    "print(f\"  Testing predictions: {y_pred_test_binary.sum()} anomalies detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "print(\"\ud83d\udcca Model Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training set performance\n",
    "print(\"\\n\ud83c\udfcb\ufe0f Training Set Performance:\")\n",
    "print(classification_report(y_train, y_pred_train_binary, \n",
    "                          target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Test set performance\n",
    "print(\"\\n\ud83e\uddea Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred_test_binary, \n",
    "                          target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Training confusion matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train_binary)\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Anomaly'], \n",
    "            yticklabels=['Normal', 'Anomaly'], ax=axes[0])\n",
    "axes[0].set_title('Training Set Confusion Matrix')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Test confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test_binary)\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Anomaly'], \n",
    "            yticklabels=['Normal', 'Anomaly'], ax=axes[1])\n",
    "axes[1].set_title('Test Set Confusion Matrix')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze anomaly scores distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Isolation Forest Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Score distribution\n",
    "axes[0, 0].hist(train_scores[~y_train], bins=50, alpha=0.7, label='Normal', density=True)\n",
    "axes[0, 0].hist(train_scores[y_train], bins=50, alpha=0.7, label='Anomaly', density=True)\n",
    "axes[0, 0].set_title('Anomaly Score Distribution (Training)')\n",
    "axes[0, 0].set_xlabel('Anomaly Score')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Score vs time (sample)\n",
    "sample_size = min(1000, len(test_scores))\n",
    "sample_indices = np.random.choice(len(test_scores), sample_size, replace=False)\n",
    "sample_indices = np.sort(sample_indices)\n",
    "\n",
    "axes[0, 1].plot(sample_indices, test_scores[sample_indices], 'b-', alpha=0.7, linewidth=1)\n",
    "anomaly_indices = sample_indices[y_test.iloc[sample_indices]]\n",
    "if len(anomaly_indices) > 0:\n",
    "    axes[0, 1].scatter(anomaly_indices, test_scores[anomaly_indices], \n",
    "                      color='red', s=30, alpha=0.8, label='True Anomalies')\n",
    "axes[0, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_title('Anomaly Scores Over Time (Test Sample)')\n",
    "axes[0, 1].set_xlabel('Sample Index')\n",
    "axes[0, 1].set_ylabel('Anomaly Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance (using PCA to visualize)\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test_scaled)\n",
    "\n",
    "normal_mask = ~y_test\n",
    "anomaly_mask = y_test\n",
    "\n",
    "axes[1, 0].scatter(X_test_pca[normal_mask, 0], X_test_pca[normal_mask, 1], \n",
    "                  c='blue', alpha=0.6, s=20, label='Normal')\n",
    "axes[1, 0].scatter(X_test_pca[anomaly_mask, 0], X_test_pca[anomaly_mask, 1], \n",
    "                  c='red', alpha=0.8, s=30, label='Anomaly')\n",
    "axes[1, 0].set_title('PCA Visualization (Test Set)')\n",
    "axes[1, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "axes[1, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Model performance metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_test_binary)\n",
    "recall = recall_score(y_test, y_pred_test_binary)\n",
    "f1 = f1_score(y_test, y_pred_test_binary)\n",
    "\n",
    "# Convert scores to probabilities for AUC calculation\n",
    "test_scores_prob = (test_scores - test_scores.min()) / (test_scores.max() - test_scores.min())\n",
    "auc = roc_auc_score(y_test, 1 - test_scores_prob)  # Invert because lower scores = more anomalous\n",
    "\n",
    "metrics_text = f\"\"\"\n",
    "Model Performance Metrics:\n",
    "\n",
    "Precision: {precision:.3f}\n",
    "Recall: {recall:.3f}\n",
    "F1-Score: {f1:.3f}\n",
    "AUC-ROC: {auc:.3f}\n",
    "\n",
    "Configuration:\n",
    "Trees: {ISOLATION_FOREST_CONFIG['n_estimators']}\n",
    "Contamination: {ISOLATION_FOREST_CONFIG['contamination']}\n",
    "Features: {X.shape[1]}\n",
    "\n",
    "Data:\n",
    "Training: {X_train.shape[0]:,}\n",
    "Testing: {X_test.shape[0]:,}\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.05, 0.95, metrics_text, transform=axes[1, 1].transAxes, \n",
    "               fontsize=10, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "axes[1, 1].set_title('Model Summary')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Model Performance Summary:\")\n",
    "print(f\"  Precision: {precision:.3f}\")\n",
    "print(f\"  Recall: {recall:.3f}\")\n",
    "print(f\"  F1-Score: {f1:.3f}\")\n",
    "print(f\"  AUC-ROC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Save Model and Upload to S3",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Save model and scaler locally\n",
    "# Use /mnt/models for persistent storage (model-storage-pvc)\n",
    "# Fallback to local for development outside cluster\n",
    "MODELS_DIR = Path('/mnt/models/predictive-analytics') if Path('/mnt/models').exists() else Path('/opt/app-root/src/models')\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = MODELS_DIR / 'isolation_forest_model.pkl'\n",
    "scaler_path = MODELS_DIR / 'isolation_forest_scaler.pkl'\n",
    "\n",
    "joblib.dump(isolation_forest, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"\ud83d\udcbe Saved Isolation Forest model to {model_path}\")\n",
    "print(f\"\ud83d\udcbe Saved scaler to {scaler_path}\")\n",
    "\n",
    "# Upload models to S3 for persistent storage\n",
    "try:\n",
    "    from common_functions import upload_model_to_s3, test_s3_connection\n",
    "    \n",
    "    if test_s3_connection():\n",
    "        upload_model_to_s3(\n",
    "            str(model_path),\n",
    "            s3_key='models/anomaly-detection/isolation_forest_model.pkl'\n",
    "        )\n",
    "        upload_model_to_s3(\n",
    "            str(scaler_path),\n",
    "            s3_key='models/anomaly-detection/isolation_forest_scaler.pkl'\n",
    "        )\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f S3 not available - models saved locally only\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0\ufe0f S3 functions not available - models saved locally only\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f S3 upload failed (non-critical): {e}\")\n",
    "\n",
    "# Verify model saved\n",
    "assert model_path.exists(), \"Model not saved\"\n",
    "assert scaler_path.exists(), \"Scaler not saved\"\n",
    "print(\"\u2705 Model artifacts saved successfully\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
