{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-Based Anomaly Detection\n",
    "\n",
    "## Overview\n",
    "This notebook implements LSTM (Long Short-Term Memory) neural networks for anomaly detection using reconstruction error. LSTMs learn normal patterns and flag deviations as anomalies.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: `synthetic-anomaly-generation.ipynb` (Phase 1)\n",
    "- GPU access (recommended)\n",
    "- PyTorch 2025.1, TensorFlow/Keras\n",
    "- Synthetic dataset: `/opt/app-root/src/data/processed/synthetic_anomalies.parquet`\n",
    "\n",
    "## Why We Use Synthetic Data\n",
    "\n",
    "### The Problem: Real Anomalies Are Rare\n",
    "In production OpenShift clusters:\n",
    "- Anomalies occur <1% of the time\n",
    "- Collecting 1000 labeled anomalies takes months/years\n",
    "- Different anomaly types are hard to capture\n",
    "- Can't deliberately cause failures to collect data\n",
    "\n",
    "### The Solution: Synthetic Anomalies\n",
    "We generate synthetic anomalies because:\n",
    "- ‚úÖ Create 1000+ labeled anomalies in minutes\n",
    "- ‚úÖ Control anomaly types and severity\n",
    "- ‚úÖ Ensure balanced training data (50% normal, 50% anomaly)\n",
    "- ‚úÖ Reproducible and testable\n",
    "- ‚úÖ Models trained on synthetic data generalize to real anomalies\n",
    "\n",
    "### Machine Learning Best Practice\n",
    "Supervised learning requires labeled data. Synthetic data provides:\n",
    "1. **Ground Truth**: Known labels for evaluation\n",
    "2. **Balanced Classes**: Equal normal and anomaly samples\n",
    "3. **Reproducibility**: Same data for consistent results\n",
    "4. **Generalization**: Models learn patterns, not memorize examples\n",
    "\n",
    "## Learning Objectives\n",
    "- Build LSTM autoencoder architecture trained on synthetic data\n",
    "- Train on GPU for efficiency\n",
    "- Use reconstruction error for anomaly detection\n",
    "- Optimize hyperparameters\n",
    "- Evaluate deep learning model performance with labeled data\n",
    "\n",
    "## Key Concepts\n",
    "- **LSTM**: Recurrent neural network for sequence learning\n",
    "- **Autoencoder**: Learns compressed representation of normal data\n",
    "- **Reconstruction Error**: Difference between input and reconstructed output\n",
    "- **GPU Acceleration**: Training on NVIDIA GPUs for speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Why Synthetic Data for Training?\n",
    "- **He & Garcia (2009)**: \"Learning from Imbalanced Data\" - https://ieeexplore.ieee.org/document/5128907\n",
    "- **Nikolenko (2021)**: \"Synthetic Data for Deep Learning\" - https://arxiv.org/abs/1909.11373\n",
    "- **Goldstein & Uchida (2016)**: \"Anomaly Detection with Robust Deep Autoencoders\" - https://arxiv.org/abs/1511.08747\n",
    "\n",
    "### LSTM and Deep Learning for Anomaly Detection\n",
    "- **Malhotra et al. (2016)**: \"Time Series Anomaly Detection with LSTM Networks\" - https://arxiv.org/abs/1607.00148\n",
    "- **Hochreiter & Schmidhuber (1997)**: \"Long Short-Term Memory\" - Classic LSTM paper\n",
    "- **Goodfellow et al. (2016)**: \"Deep Learning\" - Comprehensive deep learning reference\n",
    "\n",
    "### Key Takeaway\n",
    "Synthetic data provides labeled training examples that allow us to:\n",
    "1. Train deep learning models with known ground truth\n",
    "2. Evaluate performance with precision, recall, and F1 scores\n",
    "3. Ensure reproducible and testable results\n",
    "4. Build models that generalize to real-world anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport logging\nfrom pathlib import Path\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n        Path('/opt/app-root/src/openshift-aiops-platform/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    current = Path.cwd()\n    for _ in range(5):\n        utils_path = current / 'notebooks' / 'utils'\n        if utils_path.exists():\n            return str(utils_path)\n        current = current.parent\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"‚úÖ Utils path found: {utils_path}\")\nelse:\n    print(\"‚ö†Ô∏è Utils path not found - will use fallback implementations\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import setup_environment\n    print(\"‚úÖ Common functions imported\")\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è Common functions not available: {e}\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup environment\nenv_info = setup_environment()\nlogger.info(f\"Environment ready: {env_info}\")\n\n# Check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlogger.info(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n# Define paths\nDATA_DIR = Path('/opt/app-root/src/data')\nPROCESSED_DIR = DATA_DIR / 'processed'\n\n# Use /mnt/models for persistent storage (model-storage-pvc)\n# Fallback to local for development outside cluster\nMODELS_DIR = Path('/mnt/models') if Path('/mnt/models').exists() else Path('/opt/app-root/src/models')\n\n# Create KServe-compatible subdirectory structure\nMODEL_NAME = 'lstm-predictor'  # Separate model name from anomaly-detector\nMODEL_DIR = MODELS_DIR / MODEL_NAME\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\n\nlogger.info(f\"Models directory: {MODEL_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load or generate synthetic data\ndata_file = PROCESSED_DIR / 'synthetic_anomalies.parquet'\n\nif data_file.exists():\n    df = pd.read_parquet(data_file)\n    logger.info(f\"Loaded existing data: {df.shape}\")\nelse:\n    logger.info(\"Synthetic data not found - generating for validation...\")\n    from datetime import datetime, timedelta\n    np.random.seed(42)\n    n_points = 1000\n    n_features = 5\n    \n    start_time = datetime.now() - timedelta(days=30)\n    timestamps = [start_time + timedelta(minutes=i) for i in range(n_points)]\n    \n    data = {}\n    for i in range(n_features):\n        trend = np.linspace(50, 60, n_points)\n        seasonal = 10 * np.sin(np.linspace(0, 4*np.pi, n_points))\n        noise = np.random.normal(0, 2, n_points)\n        data[f'metric_{i}'] = trend + seasonal + noise\n    \n    df = pd.DataFrame(data)\n    df['timestamp'] = timestamps\n    df['label'] = 0\n    \n    anomaly_indices = np.random.choice(len(df), 50, replace=False)\n    for idx in anomaly_indices:\n        features = np.random.choice(5, 2, replace=False)\n        for feat in features:\n            col = f'metric_{feat}'\n            std = df[col].std()\n            df.loc[idx, col] += 3.0 * std * np.random.choice([-1, 1])\n        df.loc[idx, 'label'] = 1\n    \n    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n    df.to_parquet(data_file)\n    logger.info(f\"Generated and saved synthetic data: {df.shape}\")\n\n# Extract features (exclude timestamp and label)\nfeature_cols = [col for col in df.columns if col.startswith('metric_')]\nX = df[feature_cols].values\ny = df['label'].values\n\n# Normalize data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Note: scaler will be saved with model in a pipeline (see Cell 12)\n\nlogger.info(f\"Data shape: {X_scaled.shape}\")\nlogger.info(f\"Features: {feature_cols}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32, num_layers=2):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.LSTM(hidden_size, input_size, num_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encoded, _ = self.encoder(x)\n",
    "        # Decode\n",
    "        decoded, _ = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Create model\n",
    "model = LSTMAutoencoder(input_size=len(feature_cols), hidden_size=32, num_layers=2)\n",
    "model = model.to(device)\n",
    "logger.info(f\"Model created: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X_tensor = torch.FloatTensor(X_scaled).unsqueeze(1)  # Add sequence dimension\n",
    "dataset = TensorDataset(X_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# Train\n",
    "logger.info(\"Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        X_batch = batch[0].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, X_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        logger.info(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "logger.info(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Detect Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reconstruction errors\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_tensor_full = torch.FloatTensor(X_scaled).unsqueeze(1).to(device)\n",
    "    reconstructed = model(X_tensor_full)\n",
    "    errors = torch.mean((X_tensor_full - reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n",
    "\n",
    "# Determine threshold (95th percentile of normal data)\n",
    "normal_mask = y == 0\n",
    "threshold = np.percentile(errors[normal_mask], 95)\n",
    "\n",
    "# Predict anomalies\n",
    "lstm_preds = (errors > threshold).astype(int)\n",
    "\n",
    "logger.info(f\"Threshold: {threshold:.4f}\")\n",
    "logger.info(f\"Detected {lstm_preds.sum()} anomalies\")\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(y, lstm_preds, zero_division=0)\n",
    "recall = recall_score(y, lstm_preds, zero_division=0)\n",
    "f1 = f1_score(y, lstm_preds, zero_division=0)\n",
    "print(f\"LSTM Performance: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ‚ú® Create wrapper class to combine scaler + model (KServe compatible)\nclass LSTMPipeline:\n    \"\"\"\n    Wrapper class combining scaler + LSTM model for KServe deployment.\n    \n    This ensures KServe finds exactly ONE .pkl file in the model directory.\n    \"\"\"\n    def __init__(self, scaler, model_state_dict, model_class, model_config, threshold, device='cpu'):\n        self.scaler = scaler\n        self.model_state_dict = model_state_dict\n        self.model_class = model_class\n        self.model_config = model_config\n        self.threshold = threshold\n        self.device = device\n        self._model = None\n    \n    def _get_model(self):\n        \"\"\"Lazy load model from state dict\"\"\"\n        if self._model is None:\n            self._model = self.model_class(**self.model_config)\n            self._model.load_state_dict(self.model_state_dict)\n            self._model = self._model.to(self.device)\n            self._model.eval()\n        return self._model\n    \n    def predict(self, X):\n        \"\"\"\n        Predict anomalies using reconstruction error.\n        \n        Args:\n            X: Input features (numpy array)\n        \n        Returns:\n            Predictions: 1 for normal, -1 for anomaly (sklearn convention)\n        \"\"\"\n        # Scale input\n        X_scaled = self.scaler.transform(X)\n        \n        # Get model\n        model = self._get_model()\n        \n        # Convert to tensor\n        X_tensor = torch.FloatTensor(X_scaled).unsqueeze(1).to(self.device)\n        \n        # Get reconstruction errors\n        with torch.no_grad():\n            reconstructed = model(X_tensor)\n            errors = torch.mean((X_tensor - reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n        \n        # Predict: -1 for anomaly, 1 for normal (sklearn convention)\n        predictions = np.where(errors > self.threshold, -1, 1)\n        return predictions\n\n# Create pipeline with scaler + model\n# Note: Save model state dict (not the full model object) for portability\npipeline = LSTMPipeline(\n    scaler=scaler,\n    model_state_dict=model.state_dict(),\n    model_class=LSTMAutoencoder,\n    model_config={'input_size': len(feature_cols), 'hidden_size': 32, 'num_layers': 2},\n    threshold=threshold,\n    device='cpu'  # KServe will use CPU by default\n)\n\n# Save SINGLE pipeline file (KServe compatible)\n# KServe expects model at: /mnt/models/lstm-predictor/model.pkl\npipeline_path = MODEL_DIR / 'model.pkl'  # Changed from lstm-predictor.pkl\nwith open(pipeline_path, 'wb') as f:\n    pickle.dump(pipeline, f)\n\nlogger.info(f\"üíæ Saved LSTM pipeline to: {pipeline_path}\")\nlogger.info(f\"   ‚úÖ KServe-compatible path: {MODEL_NAME}/model.pkl\")\nlogger.info(f\"   ‚úÖ Single .pkl file (scaler + model combined)\")\n\n# Upload to S3 for persistent storage\ntry:\n    from common_functions import upload_model_to_s3, test_s3_connection\n    \n    if test_s3_connection():\n        upload_model_to_s3(\n            str(pipeline_path),\n            s3_key='models/anomaly-detection/lstm-predictor/model.pkl'\n        )\n        logger.info(f\"‚òÅÔ∏è  Uploaded to S3: models/anomaly-detection/lstm-predictor/model.pkl\")\n    else:\n        logger.info(\"‚ö†Ô∏è S3 not available - model saved locally only\")\nexcept ImportError:\n    logger.info(\"‚ö†Ô∏è S3 functions not available - model saved locally only\")\nexcept Exception as e:\n    logger.warning(f\"‚ö†Ô∏è S3 upload failed (non-critical): {e}\")\n\n# Verify pipeline saved\nassert pipeline_path.exists(), \"Pipeline not saved\"\nlogger.info(f\"\\n‚úÖ LSTM pipeline saved successfully\")\nlogger.info(f\"   Path: {pipeline_path}\")\nlogger.info(f\"   Size: {pipeline_path.stat().st_size / 1024:.2f} KB\")\n\n# Clean up old separate files if they exist\nold_files = [\n    MODELS_DIR / 'lstm_autoencoder.pt',\n    MODELS_DIR / 'lstm_scaler.pkl',\n    MODELS_DIR / 'lstm-predictor.pkl'  # Old flat file\n]\nfor old_file in old_files:\n    if old_file.exists():\n        old_file.unlink()\n        logger.info(f\"üóëÔ∏è  Removed old file: {old_file.name}\")\n\n# Save predictions\nresults_df = pd.DataFrame({\n    'actual': y,\n    'lstm_pred': lstm_preds,\n    'reconstruction_error': errors\n})\nresults_df.to_parquet(PROCESSED_DIR / 'lstm_predictions.parquet')\nlogger.info(\"Saved predictions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify outputs\nassert (MODEL_DIR / 'model.pkl').exists(), \"LSTM pipeline not saved\"\nassert (PROCESSED_DIR / 'lstm_predictions.parquet').exists(), \"Predictions not saved\"\n\nlogger.info(\"‚úÖ All validations passed\")\nprint(f\"\\nPipeline saved to: {MODEL_DIR / 'model.pkl'}\")\nprint(f\"Predictions saved to: {PROCESSED_DIR / 'lstm_predictions.parquet'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Synthetic anomalies from `synthetic-anomaly-generation.ipynb`\n",
    "- **Output**: LSTM model for `ensemble-anomaly-methods.ipynb`\n",
    "- **Deployment**: Model can be exported to KServe for production\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Compare LSTM performance with ARIMA and Prophet\n",
    "2. Proceed to `ensemble-anomaly-methods.ipynb`\n",
    "3. Combine all methods for best performance\n",
    "4. Deploy ensemble to coordination engine\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [PyTorch LSTM Documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "- [Autoencoder Anomaly Detection](https://en.wikipedia.org/wiki/Autoencoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
