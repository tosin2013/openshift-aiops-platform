{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordination Engine Integration for Self-Healing Platform\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to integrate trained anomaly detection models with the Self-Healing Platform's coordination engine. It shows the complete workflow from anomaly detection to automated remediation actions.\n",
    "\n",
    "## Prerequisites\n",
    "- Trained anomaly detection models (from 02-anomaly-detection notebooks)\n",
    "- Running coordination engine in the cluster\n",
    "- Access to OpenShift API and Prometheus metrics\n",
    "\n",
    "## Expected Outcomes\n",
    "- Understand coordination engine API and integration patterns\n",
    "- Implement real-time anomaly detection pipeline\n",
    "- Demonstrate automated remediation workflows\n",
    "- Test end-to-end self-healing scenarios\n",
    "\n",
    "## References\n",
    "- ADR-002: Hybrid Deterministic-AI Self-Healing Approach\n",
    "- ADR-009: Bootstrap Deployment Automation Architecture\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport sys\nimport os\nfrom pathlib import Path\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"\u2705 Utils path found: {utils_path}\")\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport requests\nimport json\nimport time\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Kubernetes client\ntry:\n    from kubernetes import client, config\n    k8s_available = True\n    print(\"\u2705 Kubernetes client available\")\nexcept ImportError:\n    k8s_available = False\n    print(\"\u26a0\ufe0f Kubernetes client not available - using simulation mode\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import (\n        setup_environment, print_environment_info,\n        generate_synthetic_timeseries, validate_data_quality,\n        load_processed_data\n    )\n    print(\"\u2705 Common functions imported\")\nexcept ImportError as e:\n    print(f\"\u26a0\ufe0f Using fallback implementations\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n    def print_environment_info(env_info):\n        print(f\"\ud83d\udcc1 Data dir: {env_info.get('data_dir', 'N/A')}\")\n    def generate_synthetic_timeseries(*args, **kwargs):\n        return pd.DataFrame({'value': np.random.random(100)})\n    def validate_data_quality(df, name=''):\n        return {'valid': True}\n    def load_processed_data(filename):\n        return None\n\nprint(\"\u2705 Libraries imported successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set up environment\nenv_info = setup_environment()\nprint_environment_info(env_info)\n\n# Coordination Engine Configuration\nCOORDINATION_ENGINE_CONFIG = {\n    'base_url': 'http://coordination-engine:8080',\n    'timeout': 30,\n    'retry_attempts': 3,\n    'retry_delay': 5\n}\n\n# Self-Healing Actions Configuration\nREMEDIATION_ACTIONS = {\n    'pod_restart': {\n        'description': 'Restart problematic pods',\n        'severity_threshold': 0.7,\n        'cooldown_minutes': 10\n    },\n    'scale_up': {\n        'description': 'Scale up deployment replicas',\n        'severity_threshold': 0.8,\n        'cooldown_minutes': 15\n    },\n    'resource_adjustment': {\n        'description': 'Adjust resource limits/requests',\n        'severity_threshold': 0.6,\n        'cooldown_minutes': 30\n    },\n    'alert_escalation': {\n        'description': 'Escalate to human operators',\n        'severity_threshold': 0.9,\n        'cooldown_minutes': 5\n    }\n}\n\nprint(f\"\ud83c\udfaf Coordination engine: {COORDINATION_ENGINE_CONFIG['base_url']}\")\nprint(f\"\ud83d\udd27 Available remediation actions: {len(REMEDIATION_ACTIONS)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordination Engine Client\n",
    "\n",
    "Implement client for communicating with the coordination engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class CoordinationEngineClient:\n    \"\"\"\n    Client for interacting with the Self-Healing Platform coordination engine.\n\n    This client uses the coordination engine's KServe proxy to call ML models\n    and submits incidents for remediation orchestration.\n\n    Architecture (ADR-039, ADR-040):\n        Notebook \u2192 Coordination Engine \u2192 KServe InferenceServices\n                   /api/v1/detect        (user-deployed models)\n    \"\"\"\n    \n    def __init__(self, base_url, timeout=30):\n        self.base_url = base_url.rstrip('/')\n        self.timeout = timeout\n        self.session = requests.Session()\n        \n    def health_check(self):\n        \"\"\"\n        Check if coordination engine is healthy\n        \"\"\"\n        try:\n            response = self.session.get(\n                f\"{self.base_url}/health\",\n                timeout=self.timeout\n            )\n            return response.status_code == 200\n        except Exception as e:\n            print(f\"\u274c Health check failed: {e}\")\n            return False\n    \n    def detect_anomaly(self, model_name, instances):\n        \"\"\"\n        Call coordination engine's KServe proxy for anomaly detection.\n\n        The coordination engine proxies requests to KServe InferenceServices,\n        allowing users to add custom models via values-hub.yaml configuration.\n\n        Args:\n            model_name (str): KServe model name (e.g., 'anomaly-detector', 'predictive-analytics')\n                             Users can add custom models via values-hub.yaml\n            instances (list): List of feature vectors [[f1, f2, ...]]\n\n        Returns:\n            dict: Detection results from KServe model\n                {\n                    \"predictions\": [-1, 1],  # -1=anomaly, 1=normal\n                    \"model_name\": \"anomaly-detector\",\n                    \"model_version\": \"v2\"\n                }\n\n        Example:\n            result = client.detect_anomaly(\n                model_name=\"anomaly-detector\",\n                instances=[[0.5, 1.2, 0.8]]\n            )\n        \"\"\"\n        try:\n            response = self.session.post(\n                f\"{self.base_url}/api/v1/detect\",\n                json={\n                    \"model\": model_name,\n                    \"instances\": instances\n                },\n                timeout=self.timeout\n            )\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            print(f\"\u274c Anomaly detection failed: {e}\")\n            return None\n    \n    def submit_incident(self, incident_data):\n        \"\"\"\n        Submit incident to coordination engine for remediation.\n\n        Args:\n            incident_data (dict): Incident details including anomaly info\n                {\n                    'timestamp': '2025-01-07T...',\n                    'type': 'anomaly_detected',\n                    'severity': 'high',\n                    'metrics': {...},\n                    'prediction': {...}\n                }\n\n        Returns:\n            dict: Incident ID and status\n                {\n                    'id': 'incident-123',\n                    'status': 'pending'\n                }\n        \"\"\"\n        try:\n            response = self.session.post(\n                f\"{self.base_url}/api/v1/incidents\",\n                json=incident_data,\n                timeout=self.timeout\n            )\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            print(f\"\u274c Failed to submit incident: {e}\")\n            return None\n    \n    def get_incident_status(self, incident_id):\n        \"\"\"\n        Get status of an incident\n\n        Args:\n            incident_id (str): Incident identifier\n\n        Returns:\n            dict: Incident status and remediation details\n        \"\"\"\n        try:\n            response = self.session.get(\n                f\"{self.base_url}/api/v1/incidents/{incident_id}\",\n                timeout=self.timeout\n            )\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            print(f\"\u274c Failed to get incident status: {e}\")\n            return None\n    \n    def list_models(self):\n        \"\"\"\n        List all registered KServe models available through coordination engine\n\n        Returns:\n            dict: List of available models\n                {\n                    'models': ['anomaly-detector', 'predictive-analytics', ...],\n                    'count': 2\n                }\n        \"\"\"\n        try:\n            response = self.session.get(\n                f\"{self.base_url}/api/v1/models\",\n                timeout=self.timeout\n            )\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            print(f\"\u274c Failed to list models: {e}\")\n            return None\n    \n    def get_metrics(self):\n        \"\"\"\n        Get coordination engine metrics\n        \"\"\"\n        try:\n            response = self.session.get(\n                f\"{self.base_url}/metrics\",\n                timeout=self.timeout\n            )\n            return response.status_code == 200, response.text if response.status_code == 200 else None\n        except Exception as e:\n            print(f\"\u274c Failed to get metrics: {e}\")\n            return False, None\n\n# Initialize coordination engine client\ncoord_client = CoordinationEngineClient(\n    base_url=COORDINATION_ENGINE_CONFIG['base_url'],\n    timeout=COORDINATION_ENGINE_CONFIG['timeout']\n)\n\n# Test connection\nprint(\"\ud83d\udd0d Testing coordination engine connection...\")\nif coord_client.health_check():\n    print(\"\u2705 Coordination engine is healthy\")\n    \n    # List available models (if coordination engine supports it)\n    models = coord_client.list_models()\n    if models:\n        print(f\"\ud83d\udcca Available models: {models.get('models', [])}\")\nelse:\n    print(\"\u26a0\ufe0f Coordination engine not available - using simulation mode\")\n    print(\"   Make sure coordination engine is deployed with KServe integration enabled\")\n    \nprint(\"\u2705 Coordination engine client initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Architecture: Coordination Engine as KServe Proxy\n\nThis notebook demonstrates the **production-ready architecture** where the coordination engine acts as a proxy to KServe InferenceServices.\n\n### Architecture Overview (ADR-039, ADR-040)\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Notebook     \u2502           \u2502 Coordination Engine \u2502           \u2502 KServe Models        \u2502\n\u2502                \u2502           \u2502                     \u2502           \u2502                      \u2502\n\u2502  - Extract     \u2502           \u2502 - KServe proxy      \u2502           \u2502 - anomaly-detector   \u2502\n\u2502    features    \u2502\u2500\u2500POST\u2500\u2500\u2500\u2500>\u2502 - Incident mgmt     \u2502\u2500\u2500HTTP\u2500\u2500\u2500\u2500>\u2502 - predictive-analytics\u2502\n\u2502  - Submit      \u2502           \u2502 - Remediation       \u2502           \u2502 - user-custom-models \u2502\n\u2502    incidents   \u2502<\u2500\u2500JSON\u2500\u2500\u2500>\u2502   orchestration     \u2502<\u2500\u2500JSON\u2500\u2500\u2500\u2500\u2502                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      /api/v1/detect                                               KServe v1 API\n      /api/v1/incidents\n```\n\n### Benefits\n\n- \u2705 **Central orchestration**: Coordination engine as single point of control\n- \u2705 **Easy forking**: Users modify notebook without changing ML infrastructure\n- \u2705 **Extensible**: Add custom models via `values-hub.yaml` (ADR-040)\n- \u2705 **Platform agnostic**: Works on vanilla Kubernetes and OpenShift\n- \u2705 **GitOps-native**: All configuration in version control\n\n### How It Works\n\n1. **Notebook extracts features** from metrics\n2. **Calls coordination engine** `/api/v1/detect` with model name and instances\n3. **Coordination engine proxies** to KServe InferenceService\n4. **KServe model returns** predictions\n5. **If anomaly detected**, notebook submits incident to `/api/v1/incidents`\n6. **Coordination engine orchestrates** remediation\n\n### Adding Custom Models (ADR-040)\n\nUsers can add their own KServe models in `values-hub.yaml`:\n\n```yaml\ncoordinationEngine:\n  kserve:\n    enabled: true\n    namespace: self-healing-platform\n    services:\n      # Platform default models\n      anomaly_detector: \"anomaly-detector-predictor\"\n      predictive_analytics: \"predictive-analytics-predictor\"\n      \n      # Add your custom models \u2b07\ufe0f\n      disk_failure_predictor: \"disk-failure-predictor-predictor\"\n      postgres_query_anomaly: \"postgres-query-anomaly-predictor\"\n```\n\n**Workflow**:\n1. Train model in notebook or locally\n2. Deploy as KServe InferenceService\n3. Register in `values-hub.yaml`\n4. Use from any notebook via coordination engine\n\nSee: `docs/guides/USER-MODEL-DEPLOYMENT-GUIDE.md`\n\n### No Local ML Model Needed\n\nThis notebook **does not** include a local ML model (no `AnomalyDetectionPipeline`).\nAll ML inference is handled by the coordination engine's KServe proxy."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Healing Workflow Implementation\n",
    "\n",
    "Implement the complete self-healing workflow from anomaly detection to remediation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "class SelfHealingWorkflow:\n    \"\"\"\n    Complete self-healing workflow using coordination engine.\n\n    This workflow demonstrates how to:\n    1. Extract features from metrics\n    2. Call coordination engine for anomaly detection (proxies to KServe)\n    3. Submit incidents to coordination engine for remediation\n\n    The coordination engine handles:\n    - KServe model proxy (calls InferenceServices)\n    - Incident management\n    - Remediation orchestration\n    \"\"\"\n    \n    def __init__(self, coord_client):\n        self.coord_client = coord_client  # Only need coordination engine client\n        self.remediation_history = []\n        self.cooldown_tracker = {}\n        \n    def process_metrics(self, metrics_data, model_name=\"anomaly-detector\"):\n        \"\"\"\n        Process metrics through coordination engine.\n\n        Workflow:\n        1. Extract features from metrics\n        2. Call coordination engine /api/v1/detect (proxies to KServe)\n        3. If anomaly detected, submit incident to coordination engine\n        4. Coordination engine handles remediation orchestration\n\n        Args:\n            metrics_data (dict): Metrics to analyze\n            model_name (str): KServe model to use (default: 'anomaly-detector')\n\n        Returns:\n            dict: Detection results from KServe model\n        \"\"\"\n        print(f\"\ud83d\udcca Processing metrics at {datetime.now()}\")\n        \n        # Extract features from metrics\n        features = self._extract_features(metrics_data)\n        \n        # Call coordination engine for anomaly detection (proxies to KServe)\n        print(f\"\ud83d\udd0d Calling coordination engine /api/v1/detect (model: {model_name})\")\n        detection_result = self.coord_client.detect_anomaly(\n            model_name=model_name,\n            instances=features.tolist()\n        )\n        \n        if not detection_result:\n            print(\"\u26a0\ufe0f Detection failed - coordination engine unavailable\")\n            return None\n        \n        # Check predictions\n        predictions = detection_result.get('predictions', [])\n        print(f\"\ud83d\udcca Received {len(predictions)} predictions from KServe\")\n        \n        for i, prediction in enumerate(predictions):\n            if prediction == -1:  # -1 = anomaly in sklearn IsolationForest\n                print(f\"\ud83d\udea8 Anomaly detected! (prediction: {prediction})\")\n                \n                # Create incident\n                incident = {\n                    'timestamp': datetime.now().isoformat(),\n                    'type': 'anomaly_detected',\n                    'severity': 'high',\n                    'metrics': metrics_data,\n                    'model': model_name,\n                    'prediction': prediction,\n                    'status': 'pending'\n                }\n                \n                # Submit to coordination engine for remediation\n                print(f\"\ud83d\udcdd Submitting incident to coordination engine...\")\n                incident_result = self.coord_client.submit_incident(incident)\n                \n                if incident_result:\n                    incident_id = incident_result.get('id', 'unknown')\n                    print(f\"\u2705 Incident submitted: {incident_id}\")\n                    \n                    # Track in history\n                    self.remediation_history.append({\n                        'incident_id': incident_id,\n                        'timestamp': datetime.now(),\n                        'metrics': metrics_data,\n                        'model': model_name,\n                        'prediction': prediction\n                    })\n                else:\n                    print(\"\u274c Failed to submit incident\")\n        \n        return detection_result\n    \n    def _extract_features(self, metrics_data):\n        \"\"\"\n        Extract features from metrics data.\n\n        In production, this would extract real metrics from Prometheus.\n        For demo purposes, we use the metric values directly.\n\n        Args:\n            metrics_data (dict): Metrics to convert to features\n\n        Returns:\n            np.array: Feature vector\n        \"\"\"\n        # Convert metrics to feature vector\n        features = np.array([[\n            metrics_data.get('cpu_usage', 0),\n            metrics_data.get('memory_usage', 0),\n            metrics_data.get('response_time', 0),\n            metrics_data.get('pod_count', 0)\n        ]])\n        \n        return features\n    \n    def get_remediation_summary(self):\n        \"\"\"\n        Get summary of remediation actions\n        \"\"\"\n        if not self.remediation_history:\n            return {\n                'total_incidents': 0,\n                'message': 'No incidents submitted yet'\n            }\n        \n        df = pd.DataFrame(self.remediation_history)\n        \n        summary = {\n            'total_incidents': len(df),\n            'models_used': df['model'].unique().tolist(),\n            'first_incident': df.iloc[0]['timestamp'] if len(df) > 0 else None,\n            'last_incident': df.iloc[-1]['timestamp'] if len(df) > 0 else None\n        }\n        \n        return summary\n\n# Initialize self-healing workflow\nprint(\"\ud83d\udd27 Initializing self-healing workflow...\")\nhealing_workflow = SelfHealingWorkflow(coord_client)\nprint(\"\u2705 Self-healing workflow initialized\")\nprint(\"\\n\ud83d\udccc Workflow uses coordination engine's KServe proxy for ML inference\")\nprint(\"   Models are deployed as KServe InferenceServices (ADR-039)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate different anomaly scenarios\n",
    "print(\"\ud83c\udfad Running Self-Healing Demonstration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Scenario 1: Normal metrics (should not trigger)\n",
    "print(\"\\n\ud83d\udcca Scenario 1: Normal Operations\")\n",
    "normal_metrics = {\n",
    "    'cpu_usage': 45.2,\n",
    "    'memory_usage': 62.1,\n",
    "    'pod_count': 12,\n",
    "    'response_time': 150\n",
    "}\n",
    "result1 = healing_workflow.process_metrics(normal_metrics)\n",
    "print(f\"Result: {result1['is_anomaly'].sum()} anomalies detected\")\n",
    "\n",
    "# Scenario 2: High CPU (moderate anomaly)\n",
    "print(\"\\n\ud83d\udcca Scenario 2: High CPU Usage\")\n",
    "high_cpu_metrics = {\n",
    "    'cpu_usage': 95.8,\n",
    "    'memory_usage': 68.3,\n",
    "    'pod_count': 12,\n",
    "    'response_time': 450,\n",
    "    'cpu_high': True  # Trigger feature\n",
    "}\n",
    "result2 = healing_workflow.process_metrics(high_cpu_metrics)\n",
    "print(f\"Result: {result2['is_anomaly'].sum()} anomalies detected\")\n",
    "\n",
    "# Scenario 3: Memory leak (severe anomaly)\n",
    "print(\"\\n\ud83d\udcca Scenario 3: Memory Leak Detected\")\n",
    "memory_leak_metrics = {\n",
    "    'cpu_usage': 78.2,\n",
    "    'memory_usage': 98.7,\n",
    "    'pod_count': 15,\n",
    "    'response_time': 2500,\n",
    "    'memory_leak': True  # Trigger feature\n",
    "}\n",
    "result3 = healing_workflow.process_metrics(memory_leak_metrics)\n",
    "print(f\"Result: {result3['is_anomaly'].sum()} anomalies detected\")\n",
    "\n",
    "# Scenario 4: Critical system failure\n",
    "print(\"\\n\ud83d\udcca Scenario 4: Critical System Failure\")\n",
    "critical_metrics = {\n",
    "    'cpu_usage': 99.9,\n",
    "    'memory_usage': 99.2,\n",
    "    'pod_count': 3,  # Many pods crashed\n",
    "    'response_time': 10000,\n",
    "    'cpu_high': True,\n",
    "    'memory_leak': True\n",
    "}\n",
    "result4 = healing_workflow.process_metrics(critical_metrics)\n",
    "print(f\"Result: {result4['is_anomaly'].sum()} anomalies detected\")\n",
    "\n",
    "# Wait a moment to simulate time passing\n",
    "print(\"\\n\u23f0 Waiting 2 seconds...\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Scenario 5: Test cooldown (should not trigger same action)\n",
    "print(\"\\n\ud83d\udcca Scenario 5: Testing Cooldown Period\")\n",
    "result5 = healing_workflow.process_metrics(critical_metrics)  # Same critical metrics\n",
    "print(f\"Result: {result5['is_anomaly'].sum()} anomalies detected\")\n",
    "\n",
    "print(\"\\n\ud83c\udf89 Demonstration completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate coordination engine integration\nprint(\"\ud83c\udfad Coordination Engine Integration Demo\")\nprint(\"=\" * 60)\nprint(\"\\n\ud83d\udccc Architecture: Notebook \u2192 Coordination Engine \u2192 KServe Models\")\nprint(\"   - Notebook calls /api/v1/detect\")\nprint(\"   - Coordination engine proxies to KServe InferenceService\")\nprint(\"   - If anomaly detected, submit incident via /api/v1/incidents\\n\")\n\n# Scenario 1: Normal metrics (should not trigger anomaly)\nprint(\"\\n\ud83d\udcca Scenario 1: Normal Operations\")\nprint(\"-\" * 60)\nnormal_metrics = {\n    'cpu_usage': 45.2,\n    'memory_usage': 62.1,\n    'pod_count': 12,\n    'response_time': 150\n}\nprint(f\"Metrics: {normal_metrics}\")\nresult1 = healing_workflow.process_metrics(normal_metrics, model_name=\"anomaly-detector\")\nif result1:\n    predictions = result1.get('predictions', [])\n    anomalies = sum(1 for p in predictions if p == -1)\n    print(f\"\u2705 Result: {anomalies}/{len(predictions)} anomalies detected\\n\")\n\n# Scenario 2: High CPU and response time (likely anomaly)\nprint(\"\\n\ud83d\udcca Scenario 2: High CPU & Response Time\")\nprint(\"-\" * 60)\nhigh_cpu_metrics = {\n    'cpu_usage': 95.8,\n    'memory_usage': 68.3,\n    'pod_count': 12,\n    'response_time': 1200\n}\nprint(f\"Metrics: {high_cpu_metrics}\")\nresult2 = healing_workflow.process_metrics(high_cpu_metrics, model_name=\"anomaly-detector\")\nif result2:\n    predictions = result2.get('predictions', [])\n    anomalies = sum(1 for p in predictions if p == -1)\n    print(f\"\ud83d\udcca Result: {anomalies}/{len(predictions)} anomalies detected\")\n    if anomalies > 0:\n        print(\"   \u2192 Incident submitted to coordination engine for remediation\\n\")\n\n# Scenario 3: Critical system failure (definite anomaly)\nprint(\"\\n\ud83d\udcca Scenario 3: Critical System State\")\nprint(\"-\" * 60)\ncritical_metrics = {\n    'cpu_usage': 99.9,\n    'memory_usage': 98.7,\n    'pod_count': 3,  # Many pods crashed\n    'response_time': 5000\n}\nprint(f\"Metrics: {critical_metrics}\")\nresult3 = healing_workflow.process_metrics(critical_metrics, model_name=\"anomaly-detector\")\nif result3:\n    predictions = result3.get('predictions', [])\n    anomalies = sum(1 for p in predictions if p == -1)\n    print(f\"\ud83d\udea8 Result: {anomalies}/{len(predictions)} anomalies detected\")\n    if anomalies > 0:\n        print(\"   \u2192 Incident submitted to coordination engine for remediation\\n\")\n\n# Scenario 4: Test with custom model (if available)\nprint(\"\\n\ud83d\udcca Scenario 4: Custom Model Test (Optional)\")\nprint(\"-\" * 60)\nprint(\"Testing if custom models are available...\")\nmodels_list = coord_client.list_models()\nif models_list:\n    available_models = models_list.get('models', [])\n    print(f\"\u2705 Available models: {available_models}\")\n    \n    # If there are custom models besides the default ones, try using them\n    default_models = ['anomaly-detector', 'predictive-analytics']\n    custom_models = [m for m in available_models if m not in default_models]\n    \n    if custom_models:\n        custom_model = custom_models[0]\n        print(f\"\\n\ud83d\udd2c Testing custom model: {custom_model}\")\n        result4 = healing_workflow.process_metrics(critical_metrics, model_name=custom_model)\n        if result4:\n            print(f\"\u2705 Custom model call successful!\")\n    else:\n        print(\"   No custom models deployed yet\")\n        print(\"   Users can add custom models via values-hub.yaml (see ADR-040)\")\nelse:\n    print(\"\u26a0\ufe0f Could not retrieve model list - coordination engine may not support /api/v1/models yet\")\n\nprint(\"\\n\ud83c\udf89 Demonstration completed!\")\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "code",
   "source": "# Display workflow summary\nprint(\"\ud83d\udccb Self-Healing Workflow Summary\")\nprint(\"=\" * 60)\n\nsummary = healing_workflow.get_remediation_summary()\n\nif summary.get('total_incidents', 0) > 0:\n    print(f\"Total incidents submitted: {summary['total_incidents']}\")\n    print(f\"Models used: {', '.join(summary['models_used'])}\")\n    \n    if summary.get('first_incident'):\n        print(f\"First incident: {summary['first_incident']}\")\n    if summary.get('last_incident'):\n        print(f\"Last incident: {summary['last_incident']}\")\nelse:\n    print(summary.get('message', 'No incidents submitted'))\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\\n\u2705 Self-healing workflow demonstration completed successfully!\")\nprint(\"\\n\ud83d\udd17 Next Steps:\")\nprint(\"   1. Deploy coordination engine with KServe integration (see GitHub issue #18)\")\nprint(\"   2. Ensure KServe models are deployed and healthy\")\nprint(\"   3. Run this notebook to test end-to-end integration\")\nprint(\"   4. Add custom models via values-hub.yaml (ADR-040)\")\nprint(\"\\n\ud83d\udcda References:\")\nprint(\"   - ADR-039: User-Deployed KServe Models\")\nprint(\"   - ADR-040: Extensible KServe Model Registry\")\nprint(\"   - GitHub Issue #18: Coordination Engine KServe Integration\")\nprint(\"   - docs/guides/USER-MODEL-DEPLOYMENT-GUIDE.md\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}