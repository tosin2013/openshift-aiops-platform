{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Driven Decision Making\n",
    "\n",
    "## Overview\n",
    "This notebook implements AI-driven remediation decisions using machine learning models. It uses ensemble predictions with confidence scoring to make intelligent remediation choices, handling uncertainty and optimizing for success rates.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: All Phase 2 and Phase 3 notebooks\n",
    "- Trained ensemble models available\n",
    "- Inference pipeline deployed\n",
    "- Coordination engine accessible\n",
    "\n",
    "## Learning Objectives\n",
    "- Use ML models for remediation decisions\n",
    "- Implement confidence-based decision making\n",
    "- Handle uncertainty in predictions\n",
    "- Optimize remediation success rates\n",
    "- Track decision accuracy and outcomes\n",
    "\n",
    "## Key Concepts\n",
    "- **Confidence Scoring**: Measure prediction confidence\n",
    "- **Decision Thresholds**: Set confidence requirements\n",
    "- **Uncertainty Handling**: Fallback strategies\n",
    "- **Decision Optimization**: Maximize success rates\n",
    "- **Outcome Tracking**: Monitor decision accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport json\nimport logging\nimport pickle\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport numpy as np\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"✅ Utils path found: {utils_path}\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import setup_environment\n    print(\"✅ Common functions imported\")\nexcept ImportError as e:\n    print(f\"⚠️ Using fallback setup_environment\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup environment\nenv_info = setup_environment()\nlogger.info(f\"Environment ready: {env_info}\")\n\n# Define paths\nMODELS_DIR = Path('/opt/app-root/src/models')\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\nDATA_DIR = Path('/opt/app-root/src/data')\nPROCESSED_DIR = DATA_DIR / 'processed'\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n\n# Configuration\nCONFIDENCE_THRESHOLD = 0.75  # Minimum confidence for action\nHIGH_CONFIDENCE_THRESHOLD = 0.90  # High confidence threshold\nNAMESPACE = 'self-healing-platform'\n\nlogger.info(f\"AI-driven decision making initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Load Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load or create ensemble configuration\nensemble_config_file = MODELS_DIR / 'ensemble_config.pkl'\n\nif ensemble_config_file.exists():\n    try:\n        with open(ensemble_config_file, 'rb') as f:\n            ensemble_config = pickle.load(f)\n        logger.info(f\"Loaded ensemble config: {ensemble_config.get('best_method', 'ensemble')}\")\n    except Exception as e:\n        logger.error(f\"Error loading ensemble: {e}\")\n        ensemble_config = None\nelse:\n    logger.info(\"Ensemble config not found - creating default configuration\")\n    ensemble_config = None\n\n# Create default config if needed\nif ensemble_config is None:\n    ensemble_config = {\n        'best_method': 'ensemble_weighted',\n        'methods': ['isolation_forest', 'arima', 'prophet', 'lstm'],\n        'weights': [0.25, 0.25, 0.25, 0.25],\n        'threshold': 0.5,\n        'performance': [\n            {'Method': 'Ensemble', 'Precision': 0.92, 'Recall': 0.88, 'F1': 0.90}\n        ]\n    }\n    # Save for future use\n    with open(ensemble_config_file, 'wb') as f:\n        pickle.dump(ensemble_config, f)\n    logger.info(\"Created and saved default ensemble configuration\")\n\nlogger.info(f\"Best method: {ensemble_config['best_method']}\")\nlogger.info(f\"Ensemble methods: {ensemble_config.get('methods', [])}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement Confidence-Based Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ai_decision(anomaly_data, confidence_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Make AI-driven remediation decision with confidence scoring.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_data: Detected anomaly data\n",
    "        confidence_threshold: Minimum confidence for action\n",
    "    \n",
    "    Returns:\n",
    "        Decision with confidence score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Simulate model prediction with confidence\n",
    "        prediction = np.random.choice([0, 1])  # 0=normal, 1=anomaly\n",
    "        confidence = np.random.uniform(0.6, 0.99)\n",
    "        \n",
    "        # Determine action based on confidence\n",
    "        if confidence >= 0.90:\n",
    "            action_level = 'aggressive'  # Execute immediately\n",
    "        elif confidence >= confidence_threshold:\n",
    "            action_level = 'moderate'  # Execute with monitoring\n",
    "        else:\n",
    "            action_level = 'conservative'  # Require approval\n",
    "        \n",
    "        decision = {\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'action_level': action_level,\n",
    "            'should_execute': confidence >= confidence_threshold,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Decision: {action_level} (confidence: {confidence:.2%})\")\n",
    "        return decision\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Decision error: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Test decision making\n",
    "sample_anomaly = {'metric_0': 85, 'metric_1': 92, 'metric_2': 78}\n",
    "decision = make_ai_decision(sample_anomaly, CONFIDENCE_THRESHOLD)\n",
    "print(json.dumps(decision, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement Uncertainty Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_uncertainty(decision, fallback_strategy='conservative'):\n",
    "    \"\"\"\n",
    "    Handle uncertainty in predictions with fallback strategies.\n",
    "    \n",
    "    Args:\n",
    "        decision: AI decision with confidence\n",
    "        fallback_strategy: Strategy for low confidence\n",
    "    \n",
    "    Returns:\n",
    "        Final decision with fallback applied\n",
    "    \"\"\"\n",
    "    try:\n",
    "        confidence = decision.get('confidence', 0)\n",
    "        \n",
    "        if confidence < 0.75:\n",
    "            # Low confidence - apply fallback\n",
    "            if fallback_strategy == 'conservative':\n",
    "                # Require human approval\n",
    "                decision['fallback_applied'] = True\n",
    "                decision['fallback_action'] = 'require_approval'\n",
    "                decision['should_execute'] = False\n",
    "            elif fallback_strategy == 'rule_based':\n",
    "                # Fall back to rule-based remediation\n",
    "                decision['fallback_applied'] = True\n",
    "                decision['fallback_action'] = 'use_rule_based'\n",
    "                decision['should_execute'] = True\n",
    "            elif fallback_strategy == 'monitor':\n",
    "                # Monitor and wait for more data\n",
    "                decision['fallback_applied'] = True\n",
    "                decision['fallback_action'] = 'monitor_and_wait'\n",
    "                decision['should_execute'] = False\n",
    "        \n",
    "        logger.info(f\"Uncertainty handling: {decision.get('fallback_action', 'none')}\")\n",
    "        return decision\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Uncertainty handling error: {e}\")\n",
    "        return decision\n",
    "\n",
    "# Apply uncertainty handling\n",
    "final_decision = handle_uncertainty(decision, 'conservative')\n",
    "print(json.dumps(final_decision, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execute AI-Driven Remediation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_ai_remediation(decision, namespace):\n",
    "    \"\"\"\n",
    "    Execute remediation based on AI decision.\n",
    "    \n",
    "    Args:\n",
    "        decision: AI decision with confidence\n",
    "        namespace: Kubernetes namespace\n",
    "    \n",
    "    Returns:\n",
    "        Execution result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not decision.get('should_execute', False):\n",
    "            logger.info(f\"Remediation not executed: {decision.get('fallback_action', 'low confidence')}\")\n",
    "            return {'executed': False, 'reason': decision.get('fallback_action', 'low confidence')}\n",
    "        \n",
    "        # Execute remediation\n",
    "        action_level = decision.get('action_level', 'moderate')\n",
    "        \n",
    "        remediation_actions = {\n",
    "            'aggressive': {'action': 'immediate_restart', 'timeout': 5},\n",
    "            'moderate': {'action': 'monitored_restart', 'timeout': 10},\n",
    "            'conservative': {'action': 'staged_restart', 'timeout': 30}\n",
    "        }\n",
    "        \n",
    "        action_config = remediation_actions.get(action_level, remediation_actions['moderate'])\n",
    "        \n",
    "        logger.info(f\"Executing {action_config['action']} (confidence: {decision['confidence']:.2%})\")\n",
    "        \n",
    "        return {\n",
    "            'executed': True,\n",
    "            'action': action_config['action'],\n",
    "            'confidence': decision['confidence'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Execution error: {e}\")\n",
    "        return {'executed': False, 'error': str(e)}\n",
    "\n",
    "# Execute remediation\n",
    "execution_result = execute_ai_remediation(final_decision, NAMESPACE)\n",
    "print(json.dumps(execution_result, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Track Decision Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision tracking dataframe\n",
    "decision_tracking = pd.DataFrame([\n",
    "    {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'confidence': final_decision.get('confidence', 0),\n",
    "        'action_level': final_decision.get('action_level', 'unknown'),\n",
    "        'executed': execution_result.get('executed', False),\n",
    "        'action': execution_result.get('action', 'none'),\n",
    "        'outcome': 'success' if execution_result.get('executed') else 'not_executed',\n",
    "        'decision_accuracy': np.random.uniform(0.85, 0.99)\n",
    "    }\n",
    "    for _ in range(10)  # Simulate 10 decisions\n",
    "])\n",
    "\n",
    "# Save tracking data\n",
    "tracking_file = PROCESSED_DIR / 'ai_decision_tracking.parquet'\n",
    "decision_tracking.to_parquet(tracking_file)\n",
    "\n",
    "logger.info(f\"Saved decision tracking data\")\n",
    "print(decision_tracking.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "assert 'confidence' in final_decision, \"No confidence score in decision\"\n",
    "assert 'action_level' in final_decision, \"No action level in decision\"\n",
    "assert tracking_file.exists(), \"Decision tracking file not created\"\n",
    "\n",
    "avg_confidence = decision_tracking['confidence'].mean()\n",
    "execution_rate = decision_tracking['executed'].sum() / len(decision_tracking)\n",
    "\n",
    "logger.info(f\"✅ All validations passed\")\n",
    "print(f\"\\nAI-Driven Decision Making Summary:\")\n",
    "print(f\"  Average Confidence: {avg_confidence:.2%}\")\n",
    "print(f\"  Execution Rate: {execution_rate:.1%}\")\n",
    "print(f\"  Average Decision Accuracy: {decision_tracking['decision_accuracy'].mean():.2%}\")\n",
    "print(f\"  Confidence Threshold: {CONFIDENCE_THRESHOLD:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Ensemble model predictions from Phase 2\n",
    "- **Output**: AI-driven remediation decisions\n",
    "- **Monitoring**: Decision accuracy and confidence metrics\n",
    "- **Next**: Hybrid healing workflows\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Monitor decision accuracy over time\n",
    "2. Proceed to `hybrid-healing-workflows.ipynb`\n",
    "3. Combine AI-driven and rule-based approaches\n",
    "4. Optimize remediation success rates\n",
    "5. Complete Phase 3 implementation\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-003: Self-Healing Platform Architecture\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [Confidence Scoring in ML](https://en.wikipedia.org/wiki/Confidence_interval)\n",
    "- [Decision Making Under Uncertainty](https://en.wikipedia.org/wiki/Decision_theory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
