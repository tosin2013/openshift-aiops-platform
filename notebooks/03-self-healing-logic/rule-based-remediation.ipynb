{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-Based Remediation\n",
    "\n",
    "## Overview\n",
    "This notebook implements deterministic rule-based remediation logic that maps detected anomalies to specific healing actions. Rules are executed through the coordination engine.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: All Phase 2 notebooks (anomaly detection)\n",
    "- Coordination engine running\n",
    "- Ensemble predictions available\n",
    "\n",
    "## Learning Objectives\n",
    "- Define remediation rules\n",
    "- Map anomalies to actions\n",
    "- Execute kubectl commands\n",
    "- Validate remediation success\n",
    "- Track remediation outcomes\n",
    "\n",
    "## Key Concepts\n",
    "- **Rule Engine**: Deterministic decision logic\n",
    "- **Action Mapping**: Anomaly type ‚Üí Remediation action\n",
    "- **Kubectl Integration**: Execute Kubernetes operations\n",
    "- **Validation**: Verify remediation effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Setup path for utils module\n",
    "def find_utils_path():\n",
    "    \"\"\"Find utils path regardless of current working directory\"\"\"\n",
    "    possible_paths = [\n",
    "        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n",
    "        Path.cwd() / 'notebooks' / 'utils',\n",
    "        Path.cwd().parent / 'utils',\n",
    "        Path('/workspace/repo/notebooks/utils'),\n",
    "        Path('/opt/app-root/src/notebooks/utils'),\n",
    "    ]\n",
    "    for p in possible_paths:\n",
    "        if p and p.exists() and (p / 'common_functions.py').exists():\n",
    "            return str(p)\n",
    "    return None\n",
    "\n",
    "utils_path = find_utils_path()\n",
    "if utils_path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "    print(f\"‚úÖ Utils path found: {utils_path}\")\n",
    "\n",
    "# Try to import common functions\n",
    "try:\n",
    "    from common_functions import setup_environment\n",
    "    print(\"‚úÖ Common functions imported\")\n",
    "except ImportError:\n",
    "    def setup_environment():\n",
    "        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n",
    "        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n",
    "        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n",
    "\n",
    "# Import coordination engine client\n",
    "try:\n",
    "    from coordination_engine_client import get_client\n",
    "    print(\"‚úÖ Coordination engine client imported\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Coordination engine client not available\")\n",
    "    get_client = None\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Setup environment\n",
    "env_info = setup_environment()\n",
    "logger.info(f\"Environment ready: {env_info}\")\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path('/opt/app-root/src/data')\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR = Path('/opt/app-root/src/models')\n",
    "\n",
    "logger.info(\"‚úÖ Setup complete\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Define Remediation Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define remediation rules\n",
    "REMEDIATION_RULES = {\n",
    "    'high_cpu': {\n",
    "        'description': 'High CPU usage detected',\n",
    "        'actions': [\n",
    "            {'type': 'scale', 'target': 'deployment', 'replicas': 3},\n",
    "            {'type': 'restart', 'target': 'pod'}\n",
    "        ]\n",
    "    },\n",
    "    'high_memory': {\n",
    "        'description': 'High memory usage detected',\n",
    "        'actions': [\n",
    "            {'type': 'scale', 'target': 'deployment', 'replicas': 2},\n",
    "            {'type': 'restart', 'target': 'pod'}\n",
    "        ]\n",
    "    },\n",
    "    'pod_crash': {\n",
    "        'description': 'Pod crash loop detected',\n",
    "        'actions': [\n",
    "            {'type': 'restart', 'target': 'pod'},\n",
    "            {'type': 'check_logs', 'target': 'pod'}\n",
    "        ]\n",
    "    },\n",
    "    'network_issue': {\n",
    "        'description': 'Network connectivity issue',\n",
    "        'actions': [\n",
    "            {'type': 'restart', 'target': 'pod'},\n",
    "            {'type': 'check_network', 'target': 'node'}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "logger.info(f\"Loaded {len(REMEDIATION_RULES)} remediation rules\")\n",
    "for rule_name, rule_config in REMEDIATION_RULES.items():\n",
    "    logger.info(f\"  - {rule_name}: {rule_config['description']}\")\n",
    "\n",
    "    TARGET_METRICS = [\n",
    "    # Resource Metrics (5)\n",
    "    'node_memory_utilization',      # Node memory usage %\n",
    "    'pod_cpu_usage',                # Pod CPU cores\n",
    "    'pod_memory_usage',             # Pod memory bytes\n",
    "    'alt_cpu_usage',                # Container CPU rate\n",
    "    'alt_memory_usage',             # Container RSS memory\n",
    "    \n",
    "    # Stability Metrics (3)\n",
    "    'container_restart_count',      # Total restarts\n",
    "    'container_restart_rate_1h',    # Restart velocity\n",
    "    'deployment_unavailable',       # Unavailable replicas\n",
    "    \n",
    "    # Pod Status Metrics (4)\n",
    "    'namespace_pod_count',          # Pods per namespace\n",
    "    'pods_pending',                 # Scheduling issues\n",
    "    'pods_running',                 # Healthy pods\n",
    "    'pods_failed',                  # Failed pods\n",
    "    \n",
    "    # Storage Metrics (2)\n",
    "    'persistent_volume_usage',      # PVC usage %\n",
    "    'cluster_resource_quota',       # Quota usage\n",
    "    \n",
    "    # Control Plane Metrics (2)\n",
    "    'apiserver_request_total',      # API request rate\n",
    "    'apiserver_error_rate',         # API error %\n",
    "]\n",
    "\n",
    "# Metric categories for grouping\n",
    "class MetricCategory(Enum):\n",
    "    RESOURCE = \"resource\"\n",
    "    STABILITY = \"stability\"\n",
    "    POD_STATUS = \"pod_status\"\n",
    "    STORAGE = \"storage\"\n",
    "    CONTROL_PLANE = \"control_plane\"\n",
    "\n",
    "METRIC_CATEGORIES = {\n",
    "    'node_memory_utilization': MetricCategory.RESOURCE,\n",
    "    'pod_cpu_usage': MetricCategory.RESOURCE,\n",
    "    'pod_memory_usage': MetricCategory.RESOURCE,\n",
    "    'alt_cpu_usage': MetricCategory.RESOURCE,\n",
    "    'alt_memory_usage': MetricCategory.RESOURCE,\n",
    "    'container_restart_count': MetricCategory.STABILITY,\n",
    "    'container_restart_rate_1h': MetricCategory.STABILITY,\n",
    "    'deployment_unavailable': MetricCategory.STABILITY,\n",
    "    'namespace_pod_count': MetricCategory.POD_STATUS,\n",
    "    'pods_pending': MetricCategory.POD_STATUS,\n",
    "    'pods_running': MetricCategory.POD_STATUS,\n",
    "    'pods_failed': MetricCategory.POD_STATUS,\n",
    "    'persistent_volume_usage': MetricCategory.STORAGE,\n",
    "    'cluster_resource_quota': MetricCategory.STORAGE,\n",
    "    'apiserver_request_total': MetricCategory.CONTROL_PLANE,\n",
    "    'apiserver_error_rate': MetricCategory.CONTROL_PLANE,\n",
    "}\n",
    "\n",
    "print(f\"üìä Target metrics: {len(TARGET_METRICS)}\")\n",
    "for category in MetricCategory:\n",
    "    count = sum(1 for m, c in METRIC_CATEGORIES.items() if c == category)\n",
    "    print(f\"   {category.value}: {count} metrics\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric Threshold\n",
    "METRIC_THRESHOLDS = {\n",
    "    # Resource Metrics\n",
    "    'node_memory_utilization': {\n",
    "        'warning': 75,\n",
    "        'critical': 90,\n",
    "        'unit': 'percent',\n",
    "        'direction': 'above'  # Anomaly when above threshold\n",
    "    },\n",
    "    'pod_cpu_usage': {\n",
    "        'warning': 0.8,       # 800m cores\n",
    "        'critical': 0.95,     # 950m cores\n",
    "        'unit': 'cores',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'pod_memory_usage': {\n",
    "        'warning': 500 * 1024 * 1024,   # 500MB\n",
    "        'critical': 900 * 1024 * 1024,  # 900MB\n",
    "        'unit': 'bytes',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'alt_cpu_usage': {\n",
    "        'warning': 0.8,\n",
    "        'critical': 0.95,\n",
    "        'unit': 'cores',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'alt_memory_usage': {\n",
    "        'warning': 500 * 1024 * 1024,\n",
    "        'critical': 900 * 1024 * 1024,\n",
    "        'unit': 'bytes',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    \n",
    "    # Stability Metrics\n",
    "    'container_restart_count': {\n",
    "        'warning': 3,\n",
    "        'critical': 5,\n",
    "        'unit': 'count',\n",
    "        'direction': 'above',\n",
    "        'window': '1h'\n",
    "    },\n",
    "    'container_restart_rate_1h': {\n",
    "        'warning': 2,        # 2 restarts/hour\n",
    "        'critical': 5,       # 5 restarts/hour\n",
    "        'unit': 'restarts/hour',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'deployment_unavailable': {\n",
    "        'warning': 1,\n",
    "        'critical': 2,\n",
    "        'unit': 'replicas',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    \n",
    "    # Pod Status Metrics\n",
    "    'namespace_pod_count': {\n",
    "        'warning': 100,      # Many pods might indicate issue\n",
    "        'critical': 150,\n",
    "        'unit': 'pods',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'pods_pending': {\n",
    "        'warning': 3,\n",
    "        'critical': 10,\n",
    "        'unit': 'pods',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'pods_running': {\n",
    "        'warning': 0,        # 0 running might be issue\n",
    "        'critical': 0,\n",
    "        'unit': 'pods',\n",
    "        'direction': 'below'  # Anomaly when below threshold\n",
    "    },\n",
    "    'pods_failed': {\n",
    "        'warning': 1,\n",
    "        'critical': 3,\n",
    "        'unit': 'pods',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    \n",
    "    # Storage Metrics\n",
    "    'persistent_volume_usage': {\n",
    "        'warning': 75,\n",
    "        'critical': 90,\n",
    "        'unit': 'percent',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'cluster_resource_quota': {\n",
    "        'warning': 80,\n",
    "        'critical': 95,\n",
    "        'unit': 'percent',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    \n",
    "    # Control Plane Metrics\n",
    "    'apiserver_request_total': {\n",
    "        'warning': 1000,     # High request rate\n",
    "        'critical': 5000,\n",
    "        'unit': 'requests/sec',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "    'apiserver_error_rate': {\n",
    "        'warning': 1,        # 1% error rate\n",
    "        'critical': 5,       # 5% error rate\n",
    "        'unit': 'percent',\n",
    "        'direction': 'above'\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Defined thresholds for {len(METRIC_THRESHOLDS)} metrics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: REMEDIATION ACTION TYPES (new cell)\n",
    "# =============================================================================\n",
    "\n",
    "class ActionType(Enum):\n",
    "    # Pod Actions\n",
    "    RESTART_POD = \"restart_pod\"\n",
    "    DELETE_POD = \"delete_pod\"\n",
    "    EVICT_POD = \"evict_pod\"\n",
    "    \n",
    "    # Scaling Actions\n",
    "    SCALE_UP = \"scale_up\"\n",
    "    SCALE_DOWN = \"scale_down\"\n",
    "    SCALE_HPA = \"scale_hpa\"\n",
    "    \n",
    "    # Resource Actions\n",
    "    INCREASE_LIMITS = \"increase_limits\"\n",
    "    DECREASE_LIMITS = \"decrease_limits\"\n",
    "    ADJUST_REQUESTS = \"adjust_requests\"\n",
    "    \n",
    "    # Storage Actions\n",
    "    EXPAND_PVC = \"expand_pvc\"\n",
    "    CLEANUP_STORAGE = \"cleanup_storage\"\n",
    "    \n",
    "    # Node Actions\n",
    "    CORDON_NODE = \"cordon_node\"\n",
    "    DRAIN_NODE = \"drain_node\"\n",
    "    UNCORDON_NODE = \"uncordon_node\"\n",
    "    \n",
    "    # Diagnostic Actions\n",
    "    COLLECT_LOGS = \"collect_logs\"\n",
    "    DESCRIBE_RESOURCE = \"describe_resource\"\n",
    "    CHECK_EVENTS = \"check_events\"\n",
    "    \n",
    "    # Alert Actions\n",
    "    SEND_ALERT = \"send_alert\"\n",
    "    CREATE_INCIDENT = \"create_incident\"\n",
    "    \n",
    "    # No Action\n",
    "    MONITOR_ONLY = \"monitor_only\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RemediationAction:\n",
    "    \"\"\"Single remediation action\"\"\"\n",
    "    action_type: ActionType\n",
    "    target_type: str  # pod, deployment, node, pvc, etc.\n",
    "    target_name: Optional[str] = None\n",
    "    namespace: str = \"self-healing-platform\"\n",
    "    parameters: Dict = None\n",
    "    priority: int = 1  # 1=highest\n",
    "    estimated_duration_sec: int = 30\n",
    "    requires_approval: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.parameters is None:\n",
    "            self.parameters = {}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 5: COMPREHENSIVE REMEDIATION RULES (replace existing rules cell)\n",
    "# =============================================================================\n",
    "\n",
    "# Map each metric to specific remediation rules\n",
    "REMEDIATION_RULES = {\n",
    "    # =========================================================================\n",
    "    # RESOURCE METRICS (5)\n",
    "    # =========================================================================\n",
    "    'node_memory_utilization': {\n",
    "        'description': 'High node memory utilization',\n",
    "        'category': MetricCategory.RESOURCE,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.EVICT_POD, 'pod', parameters={'selector': 'priority=low'}),\n",
    "                    RemediationAction(ActionType.SCALE_DOWN, 'deployment', parameters={'replicas_delta': -1}),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification', parameters={'channel': 'ops'}),\n",
    "                ],\n",
    "                'escalation': 'drain_node'\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'node'),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'node'),\n",
    "                    RemediationAction(ActionType.MONITOR_ONLY, 'metric'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'pod_cpu_usage': {\n",
    "        'description': 'High pod CPU usage',\n",
    "        'category': MetricCategory.RESOURCE,\n",
    "        'severity_map': {\n",
    "            'warning': 'low',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_UP, 'deployment', parameters={'replicas_delta': 1}),\n",
    "                    RemediationAction(ActionType.INCREASE_LIMITS, 'pod', parameters={'cpu': '200m'}),\n",
    "                    RemediationAction(ActionType.RESTART_POD, 'pod', priority=2),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_HPA, 'hpa', parameters={'min_replicas_delta': 1}),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'pod_memory_usage': {\n",
    "        'description': 'High pod memory usage (potential leak)',\n",
    "        'category': MetricCategory.RESOURCE,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.RESTART_POD, 'pod', priority=1),  # Fastest fix for memory leak\n",
    "                    RemediationAction(ActionType.SCALE_UP, 'deployment', parameters={'replicas_delta': 1}),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'tail': 1000}),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.INCREASE_LIMITS, 'pod', parameters={'memory': '256Mi'}),\n",
    "                    RemediationAction(ActionType.MONITOR_ONLY, 'metric', parameters={'duration': '5m'}),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'alt_cpu_usage': {\n",
    "        'description': 'High container CPU rate',\n",
    "        'category': MetricCategory.RESOURCE,\n",
    "        'severity_map': {\n",
    "            'warning': 'low',\n",
    "            'critical': 'medium'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_UP, 'deployment', parameters={'replicas_delta': 1}),\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'pod'),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.MONITOR_ONLY, 'metric'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'alt_memory_usage': {\n",
    "        'description': 'High container RSS memory',\n",
    "        'category': MetricCategory.RESOURCE,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.RESTART_POD, 'pod'),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod'),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.MONITOR_ONLY, 'metric'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STABILITY METRICS (3)\n",
    "    # =========================================================================\n",
    "    'container_restart_count': {\n",
    "        'description': 'Container restart loop detected',\n",
    "        'category': MetricCategory.STABILITY,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'critical'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'previous': True}),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'pod'),\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'pod'),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P2'}),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod'),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'pod'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'container_restart_rate_1h': {\n",
    "        'description': 'High restart velocity - crash loop likely',\n",
    "        'category': MetricCategory.STABILITY,\n",
    "        'severity_map': {\n",
    "            'warning': 'high',\n",
    "            'critical': 'critical'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_DOWN, 'deployment', parameters={'replicas': 0}, requires_approval=True),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'previous': True, 'all_containers': True}),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P1'}),\n",
    "                ],\n",
    "                'escalation': 'page_oncall'\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.RESTART_POD, 'pod'),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'deployment_unavailable': {\n",
    "        'description': 'Deployment has unavailable replicas',\n",
    "        'category': MetricCategory.STABILITY,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_UP, 'deployment', parameters={'replicas_delta': 2}),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'deployment'),\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'deployment'),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification', parameters={'channel': 'ops'}),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_UP, 'deployment', parameters={'replicas_delta': 1}),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'deployment'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # =========================================================================\n",
    "    # POD STATUS METRICS (4)\n",
    "    # =========================================================================\n",
    "    'namespace_pod_count': {\n",
    "        'description': 'Abnormal pod count in namespace',\n",
    "        'category': MetricCategory.POD_STATUS,\n",
    "        'severity_map': {\n",
    "            'warning': 'low',\n",
    "            'critical': 'medium'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'namespace'),\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'namespace'),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification'),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.MONITOR_ONLY, 'metric'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'pods_pending': {\n",
    "        'description': 'Pods stuck in Pending state - scheduling issue',\n",
    "        'category': MetricCategory.POD_STATUS,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'pod', parameters={'field_selector': 'status.phase=Pending'}),\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'pod'),\n",
    "                    RemediationAction(ActionType.UNCORDON_NODE, 'node', parameters={'selector': 'all'}),  # Try uncordoning\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P2'}),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'pod'),\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'node'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'pods_running': {\n",
    "        'description': 'No running pods - service down',\n",
    "        'category': MetricCategory.POD_STATUS,\n",
    "        'severity_map': {\n",
    "            'warning': 'high',\n",
    "            'critical': 'critical'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_UP, 'deployment', parameters={'replicas': 1}),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'deployment'),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'previous': True}),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P1'}),\n",
    "                ],\n",
    "                'escalation': 'page_oncall'\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'deployment'),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'pods_failed': {\n",
    "        'description': 'Pods in Failed state',\n",
    "        'category': MetricCategory.POD_STATUS,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.DELETE_POD, 'pod', parameters={'field_selector': 'status.phase=Failed'}),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'previous': True}),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'pod'),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification'),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod'),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'pod'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STORAGE METRICS (2)\n",
    "    # =========================================================================\n",
    "    'persistent_volume_usage': {\n",
    "        'description': 'PVC running out of space',\n",
    "        'category': MetricCategory.STORAGE,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.EXPAND_PVC, 'pvc', parameters={'increase_percent': 50}, requires_approval=True),\n",
    "                    RemediationAction(ActionType.CLEANUP_STORAGE, 'pvc', parameters={'older_than_days': 7}),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification', parameters={'channel': 'storage'}),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P2'}),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.CLEANUP_STORAGE, 'pvc', parameters={'older_than_days': 30}),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'cluster_resource_quota': {\n",
    "        'description': 'Resource quota nearly exhausted',\n",
    "        'category': MetricCategory.STORAGE,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SCALE_DOWN, 'deployment', parameters={'selector': 'priority=low', 'replicas_delta': -1}),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification', parameters={'channel': 'capacity'}),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'type': 'capacity'}),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.DESCRIBE_RESOURCE, 'resourcequota'),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification'),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONTROL PLANE METRICS (2)\n",
    "    # =========================================================================\n",
    "    'apiserver_request_total': {\n",
    "        'description': 'API server under heavy load',\n",
    "        'category': MetricCategory.CONTROL_PLANE,\n",
    "        'severity_map': {\n",
    "            'warning': 'medium',\n",
    "            'critical': 'high'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification', parameters={'channel': 'platform'}),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'namespace': 'openshift-kube-apiserver'}),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P1', 'type': 'platform'}),\n",
    "                ],\n",
    "                'escalation': 'page_platform_team'\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.MONITOR_ONLY, 'metric', parameters={'duration': '5m'}),\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'namespace': 'openshift-kube-apiserver', 'tail': 100}),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'apiserver_error_rate': {\n",
    "        'description': 'High API server error rate',\n",
    "        'category': MetricCategory.CONTROL_PLANE,\n",
    "        'severity_map': {\n",
    "            'warning': 'high',\n",
    "            'critical': 'critical'\n",
    "        },\n",
    "        'rules': [\n",
    "            {\n",
    "                'condition': 'critical',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'namespace': 'openshift-kube-apiserver', 'tail': 500}),\n",
    "                    RemediationAction(ActionType.CHECK_EVENTS, 'namespace', parameters={'namespace': 'openshift-kube-apiserver'}),\n",
    "                    RemediationAction(ActionType.CREATE_INCIDENT, 'incident', parameters={'severity': 'P1', 'type': 'platform'}),\n",
    "                ],\n",
    "                'escalation': 'page_platform_team'\n",
    "            },\n",
    "            {\n",
    "                'condition': 'warning',\n",
    "                'actions': [\n",
    "                    RemediationAction(ActionType.COLLECT_LOGS, 'pod', parameters={'namespace': 'openshift-kube-apiserver'}),\n",
    "                    RemediationAction(ActionType.SEND_ALERT, 'notification', parameters={'channel': 'platform'}),\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Defined remediation rules for {len(REMEDIATION_RULES)} metrics\")\n",
    "print(f\"\\nRules by category:\")\n",
    "for category in MetricCategory:\n",
    "    count = sum(1 for m, r in REMEDIATION_RULES.items() if r['category'] == category)\n",
    "    print(f\"   {category.value}: {count} rules\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Anomaly to Rule Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(metric_name: str, value: float) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Evaluate if a metric value exceeds thresholds.\n",
    "    \n",
    "    Args:\n",
    "        metric_name: Name of the metric\n",
    "        value: Current metric value\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (condition, severity) or (None, None) if normal\n",
    "    \"\"\"\n",
    "    if metric_name not in METRIC_THRESHOLDS:\n",
    "        return None, None\n",
    "    \n",
    "    threshold = METRIC_THRESHOLDS[metric_name]\n",
    "    direction = threshold.get('direction', 'above')\n",
    "    \n",
    "    if direction == 'above':\n",
    "        if value >= threshold['critical']:\n",
    "            return 'critical', 'critical'\n",
    "        elif value >= threshold['warning']:\n",
    "            return 'warning', 'warning'\n",
    "    else:  # below\n",
    "        if value <= threshold['critical']:\n",
    "            return 'critical', 'critical'\n",
    "        elif value <= threshold['warning']:\n",
    "            return 'warning', 'warning'\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def map_anomaly_to_rules(metric_values: Dict[str, float]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Map detected anomalies to remediation rules for ALL 16 metrics.\n",
    "    \n",
    "    Args:\n",
    "        metric_values: Dictionary of metric_name -> current_value\n",
    "    \n",
    "    Returns:\n",
    "        List of triggered rules with actions\n",
    "    \"\"\"\n",
    "    triggered_rules = []\n",
    "    \n",
    "    for metric_name, value in metric_values.items():\n",
    "        if metric_name not in REMEDIATION_RULES:\n",
    "            continue\n",
    "        \n",
    "        condition, severity = evaluate_threshold(metric_name, value)\n",
    "        \n",
    "        if condition is None:\n",
    "            continue  # Value is normal\n",
    "        \n",
    "        rule_config = REMEDIATION_RULES[metric_name]\n",
    "        \n",
    "        # Find matching rule for this condition\n",
    "        for rule in rule_config['rules']:\n",
    "            if rule['condition'] == condition:\n",
    "                triggered_rules.append({\n",
    "                    'metric': metric_name,\n",
    "                    'value': value,\n",
    "                    'threshold': METRIC_THRESHOLDS[metric_name][condition],\n",
    "                    'condition': condition,\n",
    "                    'severity': rule_config['severity_map'].get(condition, 'medium'),\n",
    "                    'description': rule_config['description'],\n",
    "                    'category': rule_config['category'].value,\n",
    "                    'actions': rule['actions'],\n",
    "                    'escalation': rule.get('escalation'),\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    # Sort by severity (critical first)\n",
    "    severity_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3}\n",
    "    triggered_rules.sort(key=lambda x: severity_order.get(x['severity'], 4))\n",
    "    \n",
    "    return triggered_rules\n",
    "\n",
    "\n",
    "# Test the mapping\n",
    "test_metrics = {\n",
    "    'node_memory_utilization': 92,    # Critical\n",
    "    'pod_cpu_usage': 0.85,            # Warning\n",
    "    'container_restart_count': 6,     # Critical\n",
    "    'pods_pending': 5,                # Warning\n",
    "    'apiserver_error_rate': 2,        # Warning\n",
    "}\n",
    "\n",
    "print(\"\\nüß™ Testing anomaly mapping:\")\n",
    "print(f\"   Input: {test_metrics}\")\n",
    "triggered = map_anomaly_to_rules(test_metrics)\n",
    "print(f\"   Triggered: {len(triggered)} rules\")\n",
    "for rule in triggered:\n",
    "    print(f\"   - [{rule['severity'].upper()}] {rule['metric']}: {rule['description']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: KUBECTL COMMAND GENERATOR (new cell)\n",
    "# =============================================================================\n",
    "\n",
    "def generate_kubectl_command(action: RemediationAction, context: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate kubectl/oc command for a remediation action.\n",
    "    \n",
    "    Args:\n",
    "        action: RemediationAction to execute\n",
    "        context: Additional context (pod_name, namespace, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        kubectl/oc command string\n",
    "    \"\"\"\n",
    "    namespace = context.get('namespace', action.namespace)\n",
    "    target_name = context.get('target_name', action.target_name) or '*'\n",
    "    \n",
    "    commands = {\n",
    "        ActionType.RESTART_POD: f\"oc delete pod {target_name} -n {namespace}\",\n",
    "        \n",
    "        ActionType.DELETE_POD: (\n",
    "            f\"oc delete pod {target_name} -n {namespace}\"\n",
    "            if action.parameters.get('field_selector') is None\n",
    "            else f\"oc delete pods --field-selector={action.parameters['field_selector']} -n {namespace}\"\n",
    "        ),\n",
    "        \n",
    "        ActionType.EVICT_POD: f\"oc adm drain {context.get('node_name', 'NODE')} --pod-selector={action.parameters.get('selector', '')} --delete-emptydir-data --ignore-daemonsets\",\n",
    "        \n",
    "        ActionType.SCALE_UP: f\"oc scale deployment/{target_name} --replicas=$(( $(oc get deployment {target_name} -n {namespace} -o jsonpath='{{.spec.replicas}}') + {action.parameters.get('replicas_delta', 1)} )) -n {namespace}\",\n",
    "        \n",
    "        ActionType.SCALE_DOWN: f\"oc scale deployment/{target_name} --replicas=$(( $(oc get deployment {target_name} -n {namespace} -o jsonpath='{{.spec.replicas}}') - {abs(action.parameters.get('replicas_delta', 1))} )) -n {namespace}\",\n",
    "        \n",
    "        ActionType.SCALE_HPA: f\"oc patch hpa {target_name} -n {namespace} --type=merge -p '{{\\\"spec\\\":{{\\\"minReplicas\\\":$(( $(oc get hpa {target_name} -n {namespace} -o jsonpath='{{.spec.minReplicas}}') + {action.parameters.get('min_replicas_delta', 1)} ))}}}}'\",\n",
    "        \n",
    "        ActionType.INCREASE_LIMITS: f\"oc set resources deployment/{target_name} -n {namespace} --limits=cpu={action.parameters.get('cpu', '500m')},memory={action.parameters.get('memory', '512Mi')}\",\n",
    "        \n",
    "        ActionType.EXPAND_PVC: f\"oc patch pvc {target_name} -n {namespace} --type=merge -p '{{\\\"spec\\\":{{\\\"resources\\\":{{\\\"requests\\\":{{\\\"storage\\\":\\\"CALCULATED_SIZE\\\"}}}}}}}}'\",\n",
    "        \n",
    "        ActionType.CLEANUP_STORAGE: f\"# Manual: Review and delete files older than {action.parameters.get('older_than_days', 30)} days in PVC {target_name}\",\n",
    "        \n",
    "        ActionType.CORDON_NODE: f\"oc adm cordon {context.get('node_name', 'NODE')}\",\n",
    "        \n",
    "        ActionType.DRAIN_NODE: f\"oc adm drain {context.get('node_name', 'NODE')} --delete-emptydir-data --ignore-daemonsets --force\",\n",
    "        \n",
    "        ActionType.UNCORDON_NODE: f\"oc adm uncordon {context.get('node_name', 'NODE')}\",\n",
    "        \n",
    "        ActionType.COLLECT_LOGS: (\n",
    "            f\"oc logs {target_name} -n {namespace} --tail={action.parameters.get('tail', 500)}\"\n",
    "            + (\" --previous\" if action.parameters.get('previous') else \"\")\n",
    "            + (\" --all-containers\" if action.parameters.get('all_containers') else \"\")\n",
    "        ),\n",
    "        \n",
    "        ActionType.DESCRIBE_RESOURCE: f\"oc describe {action.target_type} {target_name} -n {namespace}\",\n",
    "        \n",
    "        ActionType.CHECK_EVENTS: f\"oc get events -n {namespace} --sort-by='.lastTimestamp' | tail -20\",\n",
    "        \n",
    "        ActionType.SEND_ALERT: f\"# Alert to {action.parameters.get('channel', 'default')}: {{message}}\",\n",
    "        \n",
    "        ActionType.CREATE_INCIDENT: f\"# Create {action.parameters.get('severity', 'P3')} incident: {{description}}\",\n",
    "        \n",
    "        ActionType.MONITOR_ONLY: f\"# Continue monitoring {target_name} for {action.parameters.get('duration', '5m')}\",\n",
    "    }\n",
    "    \n",
    "    return commands.get(action.action_type, f\"# Unknown action: {action.action_type}\")\n",
    "\n",
    "\n",
    "# Test command generation\n",
    "test_action = RemediationAction(ActionType.RESTART_POD, 'pod')\n",
    "test_context = {'namespace': 'self-healing-platform', 'target_name': 'api-server-xyz'}\n",
    "cmd = generate_kubectl_command(test_action, test_context)\n",
    "print(f\"\\nüîß Test command: {cmd}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execute Remediation Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_remediation(\n",
    "    triggered_rules: List[Dict],\n",
    "    namespace: str = 'self-healing-platform',\n",
    "    dry_run: bool = True,\n",
    "    auto_approve: bool = False\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Execute remediation actions for triggered rules.\n",
    "    \n",
    "    Args:\n",
    "        triggered_rules: Output from map_anomaly_to_rules()\n",
    "        namespace: Target namespace\n",
    "        dry_run: If True, only generate commands without executing\n",
    "        auto_approve: If True, skip approval for requires_approval actions\n",
    "    \n",
    "    Returns:\n",
    "        List of execution results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for rule in triggered_rules:\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Processing: {rule['metric']} ({rule['severity'].upper()})\")\n",
    "        logger.info(f\"Description: {rule['description']}\")\n",
    "        logger.info(f\"Value: {rule['value']} (threshold: {rule['threshold']})\")\n",
    "        \n",
    "        rule_results = {\n",
    "            'metric': rule['metric'],\n",
    "            'severity': rule['severity'],\n",
    "            'actions': []\n",
    "        }\n",
    "        \n",
    "        for action in rule['actions']:\n",
    "            context = {\n",
    "                'namespace': namespace,\n",
    "                'target_name': None,  # Would come from incident data\n",
    "            }\n",
    "            \n",
    "            cmd = generate_kubectl_command(action, context)\n",
    "            \n",
    "            action_result = {\n",
    "                'action_type': action.action_type.value,\n",
    "                'command': cmd,\n",
    "                'requires_approval': action.requires_approval,\n",
    "                'status': 'pending'\n",
    "            }\n",
    "            \n",
    "            if action.requires_approval and not auto_approve:\n",
    "                logger.warning(f\"  ‚ö†Ô∏è REQUIRES APPROVAL: {action.action_type.value}\")\n",
    "                action_result['status'] = 'awaiting_approval'\n",
    "            elif dry_run:\n",
    "                logger.info(f\"  [DRY RUN] Would execute: {cmd[:80]}...\")\n",
    "                action_result['status'] = 'dry_run'\n",
    "            else:\n",
    "                try:\n",
    "                    logger.info(f\"  Executing: {cmd[:80]}...\")\n",
    "                    # result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=60)\n",
    "                    # action_result['stdout'] = result.stdout\n",
    "                    # action_result['stderr'] = result.stderr\n",
    "                    # action_result['status'] = 'success' if result.returncode == 0 else 'failed'\n",
    "                    action_result['status'] = 'simulated'  # For safety\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"  Error: {e}\")\n",
    "                    action_result['status'] = 'error'\n",
    "                    action_result['error'] = str(e)\n",
    "            \n",
    "            rule_results['actions'].append(action_result)\n",
    "        \n",
    "        # Check for escalation\n",
    "        if rule.get('escalation'):\n",
    "            logger.warning(f\"  üì¢ Escalation: {rule['escalation']}\")\n",
    "            rule_results['escalation'] = rule['escalation']\n",
    "        \n",
    "        results.append(rule_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Test execution\n",
    "print(\"\\nüöÄ Testing remediation execution (dry run):\")\n",
    "execution_results = execute_remediation(triggered, dry_run=True)\n",
    "print(f\"\\nExecuted {len(execution_results)} remediation rules\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submit to Coordination Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_incident_to_engine(anomaly_data: Dict, triggered_rules: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Submit incident to coordination engine with full context.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_data: Raw metric values that triggered anomalies\n",
    "        triggered_rules: Output from map_anomaly_to_rules()\n",
    "    \n",
    "    Returns:\n",
    "        Engine response\n",
    "    \"\"\"\n",
    "    incident = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'type': 'multi_metric_anomaly',\n",
    "        'metrics': anomaly_data,\n",
    "        'triggered_rules': [\n",
    "            {\n",
    "                'metric': r['metric'],\n",
    "                'severity': r['severity'],\n",
    "                'description': r['description'],\n",
    "                'category': r['category'],\n",
    "                'action_count': len(r['actions']),\n",
    "            }\n",
    "            for r in triggered_rules\n",
    "        ],\n",
    "        'overall_severity': triggered_rules[0]['severity'] if triggered_rules else 'low',\n",
    "        'status': 'pending'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        if get_client:\n",
    "            client = get_client()\n",
    "            response = client.submit_incident(incident)\n",
    "            logger.info(f\"‚úÖ Submitted incident to coordination engine\")\n",
    "            return response\n",
    "        else:\n",
    "            logger.warning(\"‚ö†Ô∏è Coordination engine client not available\")\n",
    "            return {'status': 'client_unavailable', 'incident': incident}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error submitting incident: {e}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "# Test submission (commented out for safety)\n",
    "# result = submit_incident_to_engine(test_metrics, triggered)\n",
    "print(\"\\n‚úÖ Incident submission ready\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Track Remediation Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "remediation_log = []\n",
    "\n",
    "def log_remediation(\n",
    "    incident_id: str,\n",
    "    metric: str,\n",
    "    rule_severity: str,\n",
    "    actions_executed: int,\n",
    "    success: bool,\n",
    "    duration_seconds: float,\n",
    "    escalated: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Log remediation outcome with full details.\n",
    "    \"\"\"\n",
    "    log_entry = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'incident_id': incident_id,\n",
    "        'metric': metric,\n",
    "        'severity': rule_severity,\n",
    "        'actions_executed': actions_executed,\n",
    "        'success': success,\n",
    "        'duration_seconds': duration_seconds,\n",
    "        'escalated': escalated\n",
    "    }\n",
    "    remediation_log.append(log_entry)\n",
    "    logger.info(f\"üìù Logged: {incident_id} - {metric} - {'‚úÖ' if success else '‚ùå'}\")\n",
    "\n",
    "\n",
    "# Test logging\n",
    "log_remediation('INC-001', 'node_memory_utilization', 'critical', 3, True, 15.5, escalated=True)\n",
    "log_remediation('INC-002', 'container_restart_count', 'critical', 4, True, 8.2)\n",
    "log_remediation('INC-003', 'pods_pending', 'warning', 2, True, 5.0)\n",
    "\n",
    "# Save log\n",
    "log_df = pd.DataFrame(remediation_log)\n",
    "log_df.to_parquet(PROCESSED_DIR / 'remediation_log.parquet')\n",
    "print(f\"\\nüíæ Saved remediation log: {len(remediation_log)} entries\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION \n",
    "# =============================================================================\n",
    "\n",
    "# Verify all 16 metrics have rules\n",
    "assert len(REMEDIATION_RULES) == 16, f\"Expected 16 rules, got {len(REMEDIATION_RULES)}\"\n",
    "assert len(METRIC_THRESHOLDS) == 16, f\"Expected 16 thresholds, got {len(METRIC_THRESHOLDS)}\"\n",
    "\n",
    "# Verify all TARGET_METRICS have rules\n",
    "for metric in TARGET_METRICS:\n",
    "    assert metric in REMEDIATION_RULES, f\"Missing rule for {metric}\"\n",
    "    assert metric in METRIC_THRESHOLDS, f\"Missing threshold for {metric}\"\n",
    "\n",
    "# Verify outputs\n",
    "assert (PROCESSED_DIR / 'remediation_log.parquet').exists(), \"Remediation log not saved\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL VALIDATIONS PASSED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   Target Metrics: {len(TARGET_METRICS)}\")\n",
    "print(f\"   Remediation Rules: {len(REMEDIATION_RULES)}\")\n",
    "print(f\"   Metric Thresholds: {len(METRIC_THRESHOLDS)}\")\n",
    "print(f\"   Action Types: {len(ActionType)}\")\n",
    "print(f\"   Remediation Log Entries: {len(remediation_log)}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output files:\")\n",
    "print(f\"   - {PROCESSED_DIR / 'remediation_log.parquet'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  QUICK REFERENCE (easy lookup)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã QUICK REFERENCE: Metric ‚Üí Actions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric in TARGET_METRICS:\n",
    "    rule = REMEDIATION_RULES[metric]\n",
    "    threshold = METRIC_THRESHOLDS[metric]\n",
    "    critical_actions = [a.action_type.value for a in rule['rules'][0]['actions']]\n",
    "    \n",
    "    print(f\"\\n{metric}\")\n",
    "    print(f\"  Category: {rule['category'].value}\")\n",
    "    print(f\"  Thresholds: warning={threshold['warning']}, critical={threshold['critical']} ({threshold['unit']})\")\n",
    "    print(f\"  Critical actions: {', '.join(critical_actions[:3])}{'...' if len(critical_actions) > 3 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Ensemble predictions from Phase 2\n",
    "- **Output**: Remediation actions to coordination engine\n",
    "- **Coordination Engine**: Executes remediation and tracks outcomes\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review remediation rules\n",
    "2. Proceed to `ai-driven-decision-making.ipynb`\n",
    "3. Combine rule-based and AI-driven approaches\n",
    "4. Deploy hybrid healing workflows\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-002: Hybrid Deterministic-AI Self-Healing Approach\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [Kubernetes API](https://kubernetes.io/docs/reference/generated/kubernetes-api/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
