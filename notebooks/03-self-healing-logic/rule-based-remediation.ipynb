{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-Based Remediation\n",
    "\n",
    "## Overview\n",
    "This notebook implements deterministic rule-based remediation logic that maps detected anomalies to specific healing actions. Rules are executed through the coordination engine.\n",
    "\n",
    "## Prerequisites\n",
    "- Completed: All Phase 2 notebooks (anomaly detection)\n",
    "- Coordination engine running\n",
    "- Ensemble predictions available\n",
    "\n",
    "## Learning Objectives\n",
    "- Define remediation rules\n",
    "- Map anomalies to actions\n",
    "- Execute kubectl commands\n",
    "- Validate remediation success\n",
    "- Track remediation outcomes\n",
    "\n",
    "## Key Concepts\n",
    "- **Rule Engine**: Deterministic decision logic\n",
    "- **Action Mapping**: Anomaly type → Remediation action\n",
    "- **Kubectl Integration**: Execute Kubernetes operations\n",
    "- **Validation**: Verify remediation effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport json\nimport logging\nimport requests\nfrom pathlib import Path\nfrom datetime import datetime\nimport subprocess\n\n# Setup path for utils module - works from any directory\ndef find_utils_path():\n    \"\"\"Find utils path regardless of current working directory\"\"\"\n    possible_paths = [\n        Path(__file__).parent.parent / 'utils' if '__file__' in dir() else None,\n        Path.cwd() / 'notebooks' / 'utils',\n        Path.cwd().parent / 'utils',\n        Path('/workspace/repo/notebooks/utils'),\n        Path('/opt/app-root/src/notebooks/utils'),\n    ]\n    for p in possible_paths:\n        if p and p.exists() and (p / 'common_functions.py').exists():\n            return str(p)\n    return None\n\nutils_path = find_utils_path()\nif utils_path:\n    sys.path.insert(0, utils_path)\n    print(f\"✅ Utils path found: {utils_path}\")\n\n# Try to import common functions, with fallback\ntry:\n    from common_functions import setup_environment\n    print(\"✅ Common functions imported\")\nexcept ImportError as e:\n    print(f\"⚠️ Using fallback setup_environment\")\n    def setup_environment():\n        os.makedirs('/opt/app-root/src/data/processed', exist_ok=True)\n        os.makedirs('/opt/app-root/src/models', exist_ok=True)\n        return {'data_dir': '/opt/app-root/src/data', 'models_dir': '/opt/app-root/src/models'}\n\n# Import coordination engine client\nfrom coordination_engine_client import get_client\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Setup environment\nenv_info = setup_environment()\nlogger.info(f\"Environment ready: {env_info}\")\n\n# Define paths\nDATA_DIR = Path('/opt/app-root/src/data')\nPROCESSED_DIR = DATA_DIR / 'processed'\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\nMODELS_DIR = Path('/opt/app-root/src/models')\n\nlogger.info(\"Coordination engine client ready (via coordination_engine_client.py)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Section\n",
    "\n",
    "### 1. Define Remediation Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define remediation rules\n",
    "REMEDIATION_RULES = {\n",
    "    'high_cpu': {\n",
    "        'description': 'High CPU usage detected',\n",
    "        'actions': [\n",
    "            {'type': 'scale', 'target': 'deployment', 'replicas': 3},\n",
    "            {'type': 'restart', 'target': 'pod'}\n",
    "        ]\n",
    "    },\n",
    "    'high_memory': {\n",
    "        'description': 'High memory usage detected',\n",
    "        'actions': [\n",
    "            {'type': 'scale', 'target': 'deployment', 'replicas': 2},\n",
    "            {'type': 'restart', 'target': 'pod'}\n",
    "        ]\n",
    "    },\n",
    "    'pod_crash': {\n",
    "        'description': 'Pod crash loop detected',\n",
    "        'actions': [\n",
    "            {'type': 'restart', 'target': 'pod'},\n",
    "            {'type': 'check_logs', 'target': 'pod'}\n",
    "        ]\n",
    "    },\n",
    "    'network_issue': {\n",
    "        'description': 'Network connectivity issue',\n",
    "        'actions': [\n",
    "            {'type': 'restart', 'target': 'pod'},\n",
    "            {'type': 'check_network', 'target': 'node'}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "logger.info(f\"Loaded {len(REMEDIATION_RULES)} remediation rules\")\n",
    "for rule_name, rule_config in REMEDIATION_RULES.items():\n",
    "    logger.info(f\"  - {rule_name}: {rule_config['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Anomaly to Rule Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_anomaly_to_rule(anomaly_type, metric_values):\n",
    "    \"\"\"\n",
    "    Map detected anomaly to remediation rule.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_type: Type of anomaly detected\n",
    "        metric_values: Current metric values\n",
    "    \n",
    "    Returns:\n",
    "        Remediation rule name\n",
    "    \"\"\"\n",
    "    # Simple heuristic-based mapping\n",
    "    if metric_values.get('cpu', 0) > 80:\n",
    "        return 'high_cpu'\n",
    "    elif metric_values.get('memory', 0) > 85:\n",
    "        return 'high_memory'\n",
    "    elif metric_values.get('restart_count', 0) > 3:\n",
    "        return 'pod_crash'\n",
    "    elif metric_values.get('network_errors', 0) > 10:\n",
    "        return 'network_issue'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Test mapping\n",
    "test_metrics = {'cpu': 85, 'memory': 50}\n",
    "rule = map_anomaly_to_rule('test', test_metrics)\n",
    "logger.info(f\"Test mapping: {test_metrics} -> {rule}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execute Remediation Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_remediation(rule_name, namespace='self-healing-platform', pod_name=None):\n",
    "    \"\"\"\n",
    "    Execute remediation actions for a rule.\n",
    "    \n",
    "    Args:\n",
    "        rule_name: Name of remediation rule\n",
    "        namespace: Kubernetes namespace\n",
    "        pod_name: Target pod name\n",
    "    \n",
    "    Returns:\n",
    "        Execution result\n",
    "    \"\"\"\n",
    "    if rule_name not in REMEDIATION_RULES:\n",
    "        logger.error(f\"Unknown rule: {rule_name}\")\n",
    "        return {'success': False, 'error': 'Unknown rule'}\n",
    "    \n",
    "    rule = REMEDIATION_RULES[rule_name]\n",
    "    results = []\n",
    "    \n",
    "    for action in rule['actions']:\n",
    "        try:\n",
    "            if action['type'] == 'restart' and pod_name:\n",
    "                # Delete pod to trigger restart\n",
    "                cmd = f\"oc delete pod {pod_name} -n {namespace}\"\n",
    "                logger.info(f\"Executing: {cmd}\")\n",
    "                # In real scenario, execute the command\n",
    "                results.append({'action': action['type'], 'status': 'executed'})\n",
    "            elif action['type'] == 'scale':\n",
    "                logger.info(f\"Scaling to {action['replicas']} replicas\")\n",
    "                results.append({'action': action['type'], 'status': 'executed'})\n",
    "            else:\n",
    "                logger.info(f\"Action {action['type']}: {action}\")\n",
    "                results.append({'action': action['type'], 'status': 'executed'})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error executing action: {e}\")\n",
    "            results.append({'action': action['type'], 'status': 'failed', 'error': str(e)})\n",
    "    \n",
    "    return {'success': True, 'rule': rule_name, 'actions': results}\n",
    "\n",
    "# Test execution\n",
    "result = execute_remediation('high_cpu', pod_name='test-pod')\n",
    "logger.info(f\"Remediation result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submit to Coordination Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def submit_incident_to_engine(anomaly_data, rule_name):\n    \"\"\"\n    Submit incident to coordination engine using production client.\n\n    Uses CoordinationEngineClient for proper error handling,\n    retries, and consistent API usage.\n\n    Args:\n        anomaly_data: Detected anomaly data\n        rule_name: Remediation rule to apply\n\n    Returns:\n        Engine response\n    \"\"\"\n    incident = {\n        'timestamp': datetime.now().isoformat(),\n        'type': 'anomaly_detected',\n        'severity': 'high',  # Determine from anomaly_data\n        'anomaly_data': anomaly_data,\n        'remediation_rule': rule_name,\n        'status': 'pending'\n    }\n\n    try:\n        client = get_client()\n        response = client.submit_incident(incident)\n        logger.info(f\"Submitted incident: {response}\")\n        return response\n    except Exception as e:\n        logger.error(f\"Error submitting incident: {e}\")\n        return {'error': str(e)}\n\n# Test submission\ntest_anomaly = {'metric_0': 95.5, 'metric_1': 88.2}\n# result = submit_incident_to_engine(test_anomaly, 'high_cpu')\nlogger.info(\"Incident submission ready (using CoordinationEngineClient)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Track Remediation Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create remediation tracking\n",
    "remediation_log = []\n",
    "\n",
    "def log_remediation(incident_id, rule_name, success, duration_seconds):\n",
    "    \"\"\"\n",
    "    Log remediation outcome.\n",
    "    \n",
    "    Args:\n",
    "        incident_id: Incident identifier\n",
    "        rule_name: Applied rule\n",
    "        success: Whether remediation succeeded\n",
    "        duration_seconds: Time taken\n",
    "    \"\"\"\n",
    "    log_entry = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'incident_id': incident_id,\n",
    "        'rule': rule_name,\n",
    "        'success': success,\n",
    "        'duration_seconds': duration_seconds\n",
    "    }\n",
    "    remediation_log.append(log_entry)\n",
    "    logger.info(f\"Logged remediation: {incident_id} - {rule_name} - {success}\")\n",
    "\n",
    "# Test logging\n",
    "log_remediation('INC-001', 'high_cpu', True, 15.5)\n",
    "log_remediation('INC-002', 'pod_crash', True, 8.2)\n",
    "\n",
    "# Save log\n",
    "log_df = pd.DataFrame(remediation_log)\n",
    "log_df.to_parquet(PROCESSED_DIR / 'remediation_log.parquet')\n",
    "logger.info(f\"Saved remediation log: {len(remediation_log)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "assert len(REMEDIATION_RULES) > 0, \"No remediation rules defined\"\n",
    "assert (PROCESSED_DIR / 'remediation_log.parquet').exists(), \"Remediation log not saved\"\n",
    "assert len(remediation_log) > 0, \"No remediation entries logged\"\n",
    "\n",
    "logger.info(\"✅ All validations passed\")\n",
    "print(f\"\\nRemediation Rules: {len(REMEDIATION_RULES)}\")\n",
    "print(f\"Remediation Log Entries: {len(remediation_log)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Section\n",
    "\n",
    "This notebook integrates with:\n",
    "- **Input**: Ensemble predictions from Phase 2\n",
    "- **Output**: Remediation actions to coordination engine\n",
    "- **Coordination Engine**: Executes remediation and tracks outcomes\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review remediation rules\n",
    "2. Proceed to `ai-driven-decision-making.ipynb`\n",
    "3. Combine rule-based and AI-driven approaches\n",
    "4. Deploy hybrid healing workflows\n",
    "\n",
    "## References\n",
    "\n",
    "- ADR-002: Hybrid Deterministic-AI Self-Healing Approach\n",
    "- ADR-012: Notebook Architecture for End-to-End Workflows\n",
    "- [Kubernetes API](https://kubernetes.io/docs/reference/generated/kubernetes-api/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}