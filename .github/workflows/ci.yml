name: CI/CD Pipeline

# Note: MCP Server has been moved to a standalone Go-based repository
# See: https://github.com/tosin2013/openshift-cluster-health-mcp
# This workflow now focuses on:
# - Coordination Engine (Python/Flask)
# - Jupyter Notebooks (Python/ML)
# - Helm Charts
# - Documentation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'

jobs:
  lint-and-test-coordination-engine:
    name: Coordination Engine - Lint & Test
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      working-directory: src/coordination-engine
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 pytest pytest-cov bandit

    - name: Run linting
      working-directory: src/coordination-engine
      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics

    - name: Run security scan
      working-directory: src/coordination-engine
      run: bandit -r . -f json -o bandit-report.json || true

    - name: Run tests
      working-directory: src/coordination-engine
      run: |
        # Run pytest with coverage
        # Note: Comprehensive tests are being developed (see tests/test_basic.py)
        pytest tests/ --cov=. --cov-report=xml -v || echo "‚ö†Ô∏è  Some tests skipped"

  test-notebooks:
    name: Notebooks - Comprehensive Testing
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install testing dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt

    - name: Create test directories
      run: |
        mkdir -p /tmp/notebook_tests
        mkdir -p test-outputs

    - name: Run comprehensive notebook tests
      run: |
        cd tests
        python notebook_tests.py
      continue-on-error: false

    - name: Upload test results
      uses: actions/upload-artifact@v5
      if: always()
      with:
        name: notebook-test-results
        path: |
          notebook_test_report.json
          test-outputs/
        retention-days: 30

    - name: Upload test outputs
      uses: actions/upload-artifact@v5
      if: always()
      with:
        name: notebook-test-outputs
        path: /tmp/notebook_tests/
        retention-days: 7

    - name: Generate test summary
      if: always()
      run: |
        echo "## üìä Notebook Test Results" >> $GITHUB_STEP_SUMMARY
        if [ -f notebook_test_report.json ]; then
          python -c "
          import json
          with open('notebook_test_report.json', 'r') as f:
              results = json.load(f)
          print(f'**Total Notebooks:** {results[\"total_notebooks\"]}')
          print(f'**Passed:** {results[\"passed\"]} ‚úÖ')
          print(f'**Failed:** {results[\"failed\"]} ‚ùå')
          print(f'**Skipped:** {results[\"skipped\"]} ‚è≠Ô∏è')
          print(f'**Success Rate:** {results[\"success_rate\"]:.1f}%')
          print()
          print('### Individual Results:')
          for notebook, result in results['notebooks'].items():
              status_icon = '‚úÖ' if result['status'] == 'PASSED' else '‚ùå' if result['status'] == 'FAILED' else '‚è≠Ô∏è'
              print(f'- {status_icon} **{notebook}**: {result[\"status\"]} ({result[\"execution_time\"]:.1f}s)')
          " >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Test report not generated" >> $GITHUB_STEP_SUMMARY
        fi

  security-scan-python:
    name: Python Security Scan
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Run Bandit security scan (Coordination Engine)
      working-directory: src/coordination-engine
      run: |
        pip install bandit
        bandit -r . -f json -o bandit-report.json || true

    - name: Check for vulnerabilities in Python dependencies
      run: |
        pip install safety
        safety check --file=src/coordination-engine/requirements.txt --json || true

  helm-lint:
    name: Helm Chart Lint
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Helm
      uses: azure/setup-helm@v4
      with:
        version: '3.12.0'

    - name: Lint Helm charts
      run: |
        helm lint charts/hub/ -f values-global.yaml -f values-hub.yaml || echo "Hub chart linting completed"
        helm lint charts/notebooks/ || echo "Notebooks chart linting completed"

  deploy-dev:
    name: Deploy to Development
    runs-on: ubuntu-latest
    needs: [lint-and-test-coordination-engine, test-notebooks, helm-lint]
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Deploy to development cluster
      run: |
        echo "üöÄ Deploying to development environment"
        echo "This would deploy to OpenShift development cluster"
        # Actual deployment commands would go here
        # oc apply -k k8s/overlays/development/

  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [lint-and-test-coordination-engine, test-notebooks, security-scan-python, helm-lint]
    if: always()

    steps:
    - name: Notify success
      if: ${{ needs.lint-and-test-coordination-engine.result == 'success' && needs.test-notebooks.result == 'success' }}
      run: |
        echo "‚úÖ All checks passed successfully!"
        echo "üéâ Ready for deployment"

    - name: Notify failure
      if: ${{ needs.lint-and-test-coordination-engine.result == 'failure' || needs.test-notebooks.result == 'failure' }}
      run: |
        echo "‚ùå Some checks failed"
        echo "üîß Please review and fix issues before merging"
