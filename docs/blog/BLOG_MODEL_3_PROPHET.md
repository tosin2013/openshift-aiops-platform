# Prophet for Seasonal Anomaly Detection in Kubernetes

*Handling the Monday morning traffic spike and other predictable patterns*

---

## The Monday Problem

Every Monday at 9 AM, your application traffic spikes 300%. CPU usage jumps. Memory consumption doubles. If you're using simple threshold alerts:

```yaml
# This fires every Monday morning ğŸš¨
- alert: HighCPU
  expr: container_cpu_usage > 80%
  for: 5m
```

But this isn't an anomalyâ€”it's **normal Monday behavior**.

What you need is a model that understands: *"Yes, CPU is at 85%, but it's Monday 9 AM. That's expected."*

Enter **Prophet**.

---

## What is Prophet?

**Prophet** is Facebook's open-source forecasting library designed for **business time series** with:
- Daily, weekly, and yearly seasonality
- Holiday effects
- Trend changes

### The Key Insight

Prophet decomposes time series into components:

```
y(t) = trend(t) + seasonality(t) + holidays(t) + error(t)
```

For Kubernetes metrics:
- **Trend**: Gradual growth as you add more pods/users
- **Seasonality**: Daily traffic patterns, weekly business cycles
- **Holidays**: Black Friday, year-end processing
- **Error**: The part that might be anomalous

---

## Why Prophet for Kubernetes?

### 1. Handles Multiple Seasonalities

Real applications have layered patterns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAFFIC PATTERNS IN PRODUCTION                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Daily Pattern:
    â”‚   â•­â”€â”€â”€â”€â”€â”€â•®
    â”‚  â•±        â•²         â•­â”€â”€â”€â”€â”€â”€â•®
    â”‚ â•±          â•²       â•±        â•²
    â”‚â•±            â•²â”€â”€â”€â”€â”€â•±          â•²
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
     6am  9am  12pm  3pm  6pm  9pm  12am

Weekly Pattern:
    â”‚        
    â”‚   â”Œâ”€â” â”Œâ”€â” â”Œâ”€â” â”Œâ”€â” â”Œâ”€â”
    â”‚   â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”Œâ”€â” â”Œâ”€â”
    â”‚   â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
    â””â”€â”€â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”€â–¶
        Mon Tue Wed Thu Fri Sat Sun
```

Prophet models **both patterns simultaneously**.

### 2. Robust to Missing Data

Prometheus sometimes has gaps. Prophet handles them gracefully:

```python
# Prophet doesn't care about gaps
ds            y
2024-01-01    100
2024-01-02    105
2024-01-03    NaN    # Gap - Prophet handles this
2024-01-04    NaN    # Gap
2024-01-05    112
```

### 3. Automatic Changepoint Detection

When you deploy a new version, traffic patterns might change. Prophet **automatically detects** these changepoints.

### 4. Intuitive Parameters

No need to understand (p, d, q) like ARIMA. Prophet's parameters are human-readable:

```python
model = Prophet(
    daily_seasonality=True,    # "Yes, we have daily patterns"
    weekly_seasonality=True,   # "Yes, we have weekly patterns"
    changepoint_prior_scale=0.05  # "Don't overfit to noise"
)
```

---

## How Prophet Detects Anomalies

### Step 1: Fit the Model

```python
from prophet import Prophet

# Prepare data (Prophet needs 'ds' and 'y' columns)
df_prophet = pd.DataFrame({
    'ds': timestamps,
    'y': cpu_values
})

# Fit model
model = Prophet(daily_seasonality=True, weekly_seasonality=True)
model.fit(df_prophet)
```

### Step 2: Generate Predictions with Uncertainty

```python
# Predict on the same data
forecast = model.predict(df_prophet)

# Prophet gives us:
# - yhat: predicted value
# - yhat_lower: lower bound (95% confidence)
# - yhat_upper: upper bound (95% confidence)
```

### Step 3: Flag Points Outside Bounds

```python
# Calculate residuals
residuals = df_prophet['y'] - forecast['yhat']

# Flag anomalies
threshold = 2.5 * np.std(residuals)
anomalies = np.abs(residuals) > threshold

# Or use Prophet's uncertainty bounds
anomalies = (df_prophet['y'] < forecast['yhat_lower']) | \
            (df_prophet['y'] > forecast['yhat_upper'])
```

---

## Implementation in Our Platform

### Prophet for Each Metric

```python
def detect_anomalies_prophet(series, threshold_std=2.5):
    """
    Detect anomalies using Prophet forecasting.
    
    Args:
        series: pandas Series with datetime index
        threshold_std: Standard deviations for threshold
    
    Returns:
        anomaly predictions, model, forecast
    """
    from prophet import Prophet
    import logging
    
    # Suppress Prophet's verbose logging
    logging.getLogger('cmdstanpy').setLevel(logging.WARNING)
    logging.getLogger('prophet').setLevel(logging.WARNING)
    
    # Prepare data for Prophet
    prophet_df = pd.DataFrame({
        'ds': series.index,
        'y': series.values
    }).dropna()
    
    if len(prophet_df) < 50:
        return None, None, None
    
    # Configure and fit Prophet
    model = Prophet(
        daily_seasonality=True,
        weekly_seasonality=True,
        yearly_seasonality=False,  # Need more data for this
        changepoint_prior_scale=0.05  # Regularization
    )
    model.fit(prophet_df)
    
    # Generate predictions
    forecast = model.predict(prophet_df[['ds']])
    
    # Calculate residuals
    residuals = prophet_df['y'].values - forecast['yhat'].values
    threshold = threshold_std * np.std(residuals)
    
    # Detect anomalies
    anomalies = np.abs(residuals) > threshold
    
    return anomalies, model, forecast
```

### Analyzing Multiple Metrics

```python
# Prophet is slower than ARIMA, so we prioritize key metrics
PRIORITY_METRICS = [
    'pod_cpu_usage',           # Most affected by seasonality
    'pod_memory_usage',        # Memory patterns
    'apiserver_request_total', # API traffic patterns
]

def analyze_with_prophet(df, metrics):
    """
    Run Prophet on priority metrics.
    """
    results = {}
    
    print("ğŸ“Š Running Prophet Analysis (this may take a few minutes)...")
    
    for i, metric in enumerate(metrics):
        print(f"\n[{i+1}/{len(metrics)}] {metric}...", end=" ")
        
        series = df[metric]
        anomalies, model, forecast = detect_anomalies_prophet(series)
        
        if anomalies is not None:
            results[metric] = {
                'anomalies': anomalies,
                'model': model,
                'forecast': forecast
            }
            print(f"âœ… {np.sum(anomalies)} anomalies")
        else:
            print("âŒ Failed")
    
    return results
```

---

## Real-World Example: The Monday Spike

### The Scenario

Your e-commerce application has this traffic pattern:

```
                   CPU Usage by Day/Hour
           Mon   Tue   Wed   Thu   Fri   Sat   Sun
    6am    30%   30%   30%   30%   30%   20%   15%
    9am    85%   80%   80%   80%   75%   35%   20%  â† Monday spike!
   12pm    70%   70%   70%   70%   70%   40%   25%
    3pm    75%   75%   75%   75%   70%   45%   30%
    6pm    60%   60%   60%   60%   55%   50%   35%
    9pm    40%   40%   40%   40%   35%   30%   25%
```

### Simple Threshold: False Positive

```yaml
# Alert: CPU > 80%
# Monday 9am: ALERT! (85% CPU)
# Tuesday 9am: ALERT! (80% CPU)
# Wednesday 9am: Alert... wait, is this really a problem?
```

### Prophet: Smart Detection

```python
# Prophet learns the pattern:
# "Monday 9am is expected to be 82-88%"
# "Tuesday 9am is expected to be 78-84%"

# Prophet predictions for a Monday:
# 9am: predicted=85%, actual=85% â†’ Normal âœ…
# 9am: predicted=85%, actual=95% â†’ Anomaly! âŒ (10% above expected)
```

### Visualization

```
     CPU Usage - Monday
100% â”¤
     â”‚         â•­â”€â”€â”€â•®
 90% â”¤        â•±     â•²
     â”‚       â•±       â•²        â† Actual (normal Monday)
 80% â”¤â”€â”€â”€â”€â”€â”€â•¯â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²â”€â”€â”€â”€â”€â”€â”€â”€ Prophet's prediction
     â”‚                 â•²
 70% â”¤                  â•²
     â”‚                   â•²
 60% â”¤                    â•²â”€â”€â”€â”€
     â”‚
 50% â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
     6am   9am   12pm   3pm   6pm


     CPU Usage - Monday (Anomaly!)
100% â”¤           â—
     â”‚         â•±  â•²
 95% â”¤        â•±    â•²           â† Actual (10% above expected!)
     â”‚       â•±      â•²
 90% â”¤      â•±        â•²
     â”‚     â•±          â•²
 85% â”¤â”€â”€â”€â”€â•¯â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²â”€â”€â”€â”€â”€â”€ Prophet's prediction
     â”‚                  â•²
 80% â”¤                   â•²
     â”‚
 75% â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
     
     Gap between actual and prediction = ANOMALY
```

---

## Performance Results

### Test Configuration

- **1,000 data points** (simulated with daily/weekly seasonality)
- **16 metrics** (3 analyzed with Prophet due to speed)
- **50 injected anomalies**

### Results

| Metric | Anomalies Detected | Precision | Recall |
|--------|-------------------|-----------|--------|
| pod_cpu_usage | 12 | 0.83 | 0.50 |
| pod_memory_usage | 9 | 0.78 | 0.35 |
| apiserver_request_total | 7 | 0.86 | 0.30 |

### Ensemble Results

| Method | Precision | Recall | F1 Score |
|--------|-----------|--------|----------|
| **ANY metric** | 0.70 | 0.56 | 0.62 |
| **MAJORITY** | 0.79 | 0.44 | 0.56 |

### Note on Performance

Prophet has lower recall than Isolation Forest because it's **conservative**â€”it only flags points that break seasonal patterns, not all outliers.

---

## Pros and Cons

### âœ… Strengths

| Strength | Why It Matters |
|----------|----------------|
| **Seasonality handling** | Understands daily/weekly cycles |
| **Intuitive parameters** | No ARIMA (p,d,q) tuning |
| **Uncertainty intervals** | Built-in confidence bounds |
| **Robust to missing data** | Handles gaps gracefully |
| **Visual diagnostics** | Great plotting built-in |

### âš ï¸ Limitations

| Limitation | Mitigation |
|------------|------------|
| **Slow training** | Analyze only key metrics |
| **Needs more data** | 2+ weeks for daily seasonality |
| **Univariate** | Run per metric separately |
| **Python dependency** | cmdstanpy installation can be tricky |
| **Conservative** | Combine with other models |

---

## Prophet vs ARIMA vs Isolation Forest

| Aspect | Isolation Forest | ARIMA | Prophet |
|--------|------------------|-------|---------|
| **Best for** | Point outliers | Trend deviations | Seasonal breaks |
| **Speed** | Very fast | Fast | Slow |
| **Seasonality** | âŒ No | âŒ No | âœ… Yes |
| **Setup** | Easy | Medium | Easy |
| **Data needed** | 50+ points | 50+ points | 200+ points |
| **Interpretable** | Medium | High | High |

**Use all three!** Each catches different anomaly types.

---

## Code: Complete Implementation

```python
"""
Prophet-based Anomaly Detection for Kubernetes Time Series
"""

import numpy as np
import pandas as pd
import warnings
from sklearn.metrics import precision_score, recall_score, f1_score

warnings.filterwarnings('ignore')


class ProphetAnomalyDetector:
    """
    Prophet-based anomaly detector for Kubernetes metrics.
    Best for detecting seasonality breaks.
    """
    
    def __init__(self, threshold_std=2.5, daily_seasonality=True, weekly_seasonality=True):
        self.threshold_std = threshold_std
        self.daily_seasonality = daily_seasonality
        self.weekly_seasonality = weekly_seasonality
        self.models = {}
        self.forecasts = {}
    
    def _fit_metric(self, series, metric_name):
        """Fit Prophet to a single metric."""
        try:
            from prophet import Prophet
            import logging
            logging.getLogger('cmdstanpy').setLevel(logging.WARNING)
            logging.getLogger('prophet').setLevel(logging.WARNING)
        except ImportError:
            print("Prophet not installed. Run: pip install prophet")
            return None
        
        # Prepare data
        prophet_df = pd.DataFrame({
            'ds': series.index if hasattr(series.index, 'to_pydatetime') 
                  else pd.date_range(end=pd.Timestamp.now(), periods=len(series), freq='1min'),
            'y': series.values
        }).dropna().reset_index(drop=True)
        
        if len(prophet_df) < 50:
            return None
        
        try:
            # Configure model
            model = Prophet(
                daily_seasonality=self.daily_seasonality,
                weekly_seasonality=self.weekly_seasonality,
                yearly_seasonality=False,
                changepoint_prior_scale=0.05
            )
            model.fit(prophet_df)
            
            # Generate forecast
            forecast = model.predict(prophet_df[['ds']])
            
            # Calculate residuals and threshold
            residuals = prophet_df['y'].values - forecast['yhat'].values
            threshold = self.threshold_std * np.std(residuals)
            
            # Detect anomalies
            anomalies = np.abs(residuals) > threshold
            
            # Store model and forecast
            self.models[metric_name] = model
            self.forecasts[metric_name] = forecast
            
            # Create full-length array
            full_anomalies = np.zeros(len(series), dtype=int)
            for i, is_anomaly in enumerate(anomalies):
                if is_anomaly and i < len(full_anomalies):
                    full_anomalies[i] = 1
            
            return full_anomalies
            
        except Exception as e:
            print(f"  âš ï¸ Prophet failed for {metric_name}: {str(e)[:50]}")
            return None
    
    def fit_predict(self, df, metrics):
        """
        Fit Prophet to multiple metrics.
        
        Note: Prophet is slow, so consider limiting metrics.
        """
        results = {}
        
        print("=" * 60)
        print("Prophet Anomaly Detection")
        print("=" * 60)
        print("Note: Prophet is slower than other methods. Be patient!")
        
        for i, metric in enumerate(metrics):
            print(f"\n[{i+1}/{len(metrics)}] Analyzing: {metric}...", end=" ")
            
            anomalies = self._fit_metric(df[metric], metric)
            
            if anomalies is not None:
                results[metric] = anomalies
                print(f"âœ… {np.sum(anomalies)} anomalies")
            else:
                print("âŒ Failed")
        
        if not results:
            return None
        
        # Combine results
        combined_df = pd.DataFrame(results)
        
        ensemble_any = (combined_df.sum(axis=1) > 0).astype(int).values
        ensemble_majority = (combined_df.sum(axis=1) > len(results) / 2).astype(int).values
        
        print(f"\n{'='*60}")
        print(f"Results:")
        print(f"  Metrics analyzed: {len(results)}")
        print(f"  ANY method: {ensemble_any.sum()} anomalies")
        print(f"  MAJORITY method: {ensemble_majority.sum()} anomalies")
        print(f"{'='*60}")
        
        return {
            'per_metric': results,
            'ensemble_any': ensemble_any,
            'ensemble_majority': ensemble_majority
        }
    
    def plot_forecast(self, metric_name):
        """Plot the forecast with components."""
        if metric_name not in self.models:
            print(f"No model for {metric_name}")
            return
        
        model = self.models[metric_name]
        forecast = self.forecasts[metric_name]
        
        # Prophet has built-in plotting
        fig1 = model.plot(forecast)
        fig2 = model.plot_components(forecast)
        
        return fig1, fig2
    
    def get_seasonality(self, metric_name):
        """Get the learned seasonality patterns."""
        if metric_name not in self.forecasts:
            return None
        
        forecast = self.forecasts[metric_name]
        
        return {
            'daily': forecast['daily'].values if 'daily' in forecast else None,
            'weekly': forecast['weekly'].values if 'weekly' in forecast else None,
            'trend': forecast['trend'].values
        }


# Fallback for when Prophet is not available
class StatisticalSeasonalDetector:
    """
    Simple seasonal detector when Prophet is not available.
    Uses rolling statistics to detect anomalies.
    """
    
    def __init__(self, window=60, threshold_std=2.5):
        self.window = window
        self.threshold_std = threshold_std
    
    def fit_predict(self, df, metrics):
        """Detect anomalies using rolling statistics."""
        results = {}
        
        print("Using statistical fallback (Prophet not available)")
        
        for metric in metrics:
            series = df[metric]
            
            # Rolling mean and std
            rolling_mean = series.rolling(window=self.window).mean()
            rolling_std = series.rolling(window=self.window).std()
            
            # Anomaly if outside rolling bounds
            threshold = self.threshold_std * rolling_std
            anomalies = np.abs(series - rolling_mean) > threshold
            
            results[metric] = anomalies.fillna(False).astype(int).values
        
        combined_df = pd.DataFrame(results)
        ensemble_any = (combined_df.sum(axis=1) > 0).astype(int).values
        
        return {
            'per_metric': results,
            'ensemble_any': ensemble_any
        }


# Usage example
if __name__ == "__main__":
    # Load data
    df = pd.read_parquet('prometheus_metrics.parquet')
    
    # Priority metrics for Prophet (it's slow)
    priority_metrics = [
        'pod_cpu_usage',
        'pod_memory_usage',
        'apiserver_request_total'
    ]
    
    # Try Prophet, fall back to statistical if not available
    try:
        from prophet import Prophet
        detector = ProphetAnomalyDetector()
    except ImportError:
        print("Prophet not available, using statistical fallback")
        detector = StatisticalSeasonalDetector()
    
    # Run detection
    results = detector.fit_predict(df, priority_metrics)
    
    # Evaluate
    if results and 'label' in df.columns:
        y_true = df['label'].values[:len(results['ensemble_any'])]
        y_pred = results['ensemble_any']
        
        print(f"\nPerformance:")
        print(f"  Precision: {precision_score(y_true, y_pred, zero_division=0):.3f}")
        print(f"  Recall: {recall_score(y_true, y_pred, zero_division=0):.3f}")
        print(f"  F1: {f1_score(y_true, y_pred, zero_division=0):.3f}")
```

---

## Key Takeaways

1. **Prophet excels at seasonal data**: If your metrics have daily/weekly patterns, Prophet understands them
2. **It's slower than alternatives**: Only use on key metrics
3. **Conservative detection**: Lower recall but fewer false positives
4. **Great visualizations**: Built-in plotting for debugging
5. **Combine with Isolation Forest and ARIMA** for comprehensive coverage

---

## What's Next?

In the next post, we'll cover **LSTM for sequence anomaly detection**â€”using deep learning to catch complex patterns that statistical methods miss.

---

*Part 3 of 5 in our "ML Models for Kubernetes Self-Healing" series*

*Tags: #machinelearning #prophet #timeseries #kubernetes #seasonality*
